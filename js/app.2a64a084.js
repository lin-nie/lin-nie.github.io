(function(t){function e(e){for(var o,a,s=e[0],c=e[1],p=e[2],g=0,l=[];g<s.length;g++)a=s[g],Object.prototype.hasOwnProperty.call(r,a)&&r[a]&&l.push(r[a][0]),r[a]=0;for(o in c)Object.prototype.hasOwnProperty.call(c,o)&&(t[o]=c[o]);h&&h(e);while(l.length)l.shift()();return i.push.apply(i,p||[]),n()}function n(){for(var t,e=0;e<i.length;e++){for(var n=i[e],o=!0,s=1;s<n.length;s++){var c=n[s];0!==r[c]&&(o=!1)}o&&(i.splice(e--,1),t=a(a.s=n[0]))}return t}var o={},r={app:0},i=[];function a(e){if(o[e])return o[e].exports;var n=o[e]={i:e,l:!1,exports:{}};return t[e].call(n.exports,n,n.exports,a),n.l=!0,n.exports}a.m=t,a.c=o,a.d=function(t,e,n){a.o(t,e)||Object.defineProperty(t,e,{enumerable:!0,get:n})},a.r=function(t){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(t,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(t,"__esModule",{value:!0})},a.t=function(t,e){if(1&e&&(t=a(t)),8&e)return t;if(4&e&&"object"===typeof t&&t&&t.__esModule)return t;var n=Object.create(null);if(a.r(n),Object.defineProperty(n,"default",{enumerable:!0,value:t}),2&e&&"string"!=typeof t)for(var o in t)a.d(n,o,function(e){return t[e]}.bind(null,o));return n},a.n=function(t){var e=t&&t.__esModule?function(){return t["default"]}:function(){return t};return a.d(e,"a",e),e},a.o=function(t,e){return Object.prototype.hasOwnProperty.call(t,e)},a.p="";var s=window["webpackJsonp"]=window["webpackJsonp"]||[],c=s.push.bind(s);s.push=e,s=s.slice();for(var p=0;p<s.length;p++)e(s[p]);var h=c;i.push([0,"chunk-vendors"]),n()})({0:function(t,e,n){t.exports=n("cd49")},"0554":function(t,e,n){t.exports=n.p+"img/0.3cffc5ad.png"},"0558":function(t,e,n){},"064c":function(t,e,n){t.exports=n.p+"img/1.17b8ddf2.png"},"071d":function(t,e,n){"use strict";n("14e4")},"0aa0":function(t,e,n){"use strict";n("bc6e")},"0cad":function(t,e,n){"use strict";n("0558")},"0ced":function(t,e,n){t.exports=n.p+"img/1.ff7e5f6e.png"},"0db5":function(t,e,n){t.exports=n.p+"img/0.a86f88b4.gif"},"14e4":function(t,e,n){},"19f8":function(t,e,n){},"1c8f":function(t,e,n){},"1dd2":function(t,e,n){"use strict";n("766e")},2155:function(t,e,n){t.exports=n.p+"img/NUS.e8930f16.jpg"},"22e7":function(t,e,n){var o={"./NUS.jpg":"2155","./TORONTO.jpg":"ccb7","./清华大学.jpg":"23f8","./香港科技大学.jpg":"297f"};function r(t){var e=i(t);return n(e)}function i(t){if(!n.o(o,t)){var e=new Error("Cannot find module '"+t+"'");throw e.code="MODULE_NOT_FOUND",e}return o[t]}r.keys=function(){return Object.keys(o)},r.resolve=i,t.exports=r,r.id="22e7"},"23f8":function(t,e,n){t.exports=n.p+"img/清华大学.c111f20f.jpg"},2643:function(t,e,n){"use strict";n("b449")},"297f":function(t,e,n){t.exports=n.p+"img/香港科技大学.e64963c4.jpg"},"2d4f":function(t,e,n){t.exports=n.p+"img/1.d7893ebd.gif"},"331a":function(t,e,n){"use strict";n("e199")},"37cb":function(t,e,n){},"3a96":function(t,e,n){var o={"./0.png":"5fd6","./1.png":"0ced","./2.png":"714a","./x.png":"b976","./xx.png":"cfa2","./xxx.png":"4da8"};function r(t){var e=i(t);return n(e)}function i(t){if(!n.o(o,t)){var e=new Error("Cannot find module '"+t+"'");throw e.code="MODULE_NOT_FOUND",e}return o[t]}r.keys=function(){return Object.keys(o)},r.resolve=i,t.exports=r,r.id="3a96"},"3c15":function(t,e,n){"use strict";n("19f8")},4382:function(t,e,n){t.exports=n.p+"img/2.19e7276e.gif"},"4da8":function(t,e,n){t.exports=n.p+"img/xxx.e4047474.png"},"4f9b":function(t,e,n){},5574:function(t,e,n){},"55ba":function(t,e,n){},"5d3f":function(t,e,n){"use strict";n("bdb4")},"5fd6":function(t,e,n){t.exports=n.p+"img/0.d6279389.png"},"63bf":function(t,e,n){},"6e86":function(t,e,n){"use strict";n("37cb")},"714a":function(t,e,n){t.exports=n.p+"img/2.4f5481f0.png"},"728c":function(t,e,n){},"766e":function(t,e,n){},"8aa4":function(t,e,n){},"8c41":function(t,e,n){"use strict";n("55ba")},9591:function(t,e,n){"use strict";n("5574")},"9af6":function(t,e,n){"use strict";n("8aa4")},"9dee":function(t,e,n){"use strict";n("a9be")},a69c:function(t,e,n){"use strict";n("4f9b")},a9be:function(t,e,n){},b449:function(t,e,n){},b976:function(t,e,n){t.exports=n.p+"img/x.bbfff928.png"},bc6e:function(t,e,n){},bdb4:function(t,e,n){},ccb7:function(t,e,n){t.exports=n.p+"img/TORONTO.084008c3.jpg"},cd49:function(t,e,n){"use strict";n.r(e);var o=n("2b0e"),r=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{attrs:{id:"app"}},[e("Header"),e("div",{staticClass:"container href",attrs:{id:"Home"}},[e("Profile"),e("info-list"),e("NavigationBar"),e("New"),e("ResearchInterest"),e("Publication"),e("Projects"),e("Biography"),e("ProfessionalExperience"),e("Honors"),e("Patent"),e("SoftwareCopyrght"),e("ScientificFund"),e("Footer")],1)],1)},i=[],a=n("9ab4"),s=n("1b40"),c=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"header-wrapper"},[e("div",{staticClass:"content-wrapper"},[e("div",{staticClass:"left"},[e("div",{staticClass:"name"},[e("span",[t._v(t._s(t.words.name))])]),e("div",{staticClass:"blog"},[t._v(t._s(t.words.blog))])]),e("div",{staticClass:"right"},t._l(t.LanguageItems,(function(n,o){return e("div",{key:o,staticClass:"language-item",on:{click:()=>t.changeLanguage(n)}},[t._v(" "+t._s(n.__identity)+" ")])})),0)])])},p=[],h=(n("e9f5"),n("ab43"),n("4bb5"));let g=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t])}changeLanguage(t){this.$store.dispatch("setLanguage",t.__langKey)}};Object(a["a"])([Object(s["b"])()],g.prototype,"msg",void 0),Object(a["a"])([Object(h["a"])("words")],g.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],g.prototype,"dictionary",void 0),g=Object(a["a"])([s["a"]],g);var l=g,d=l,u=(n("9af6"),n("2877")),f=Object(u["a"])(d,c,p,!1,null,"7eb63195",null),m=f.exports,w=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"info-list-wrapper"},[t._l(t.longInfoList,(function(n,o){return e("div",{key:o,staticClass:"long-info-list list-item"},[e("font-awesome-icon",{staticClass:"icon",attrs:{icon:n.icon}}),t._v(" "+t._s(n.msg)+" ")],1)})),e("div",{staticClass:"short-list-wrapper"},t._l(t.shortInfoList,(function(n,o){return e("div",{key:o,staticClass:"short-info-list list-item"},[e("font-awesome-icon",{staticClass:"icon",attrs:{icon:n.icon}}),t._v(" "+t._s(n.msg)+" ")],1)})),0),e("div",{staticClass:"icons"},t._l(t.icons,(function(n,o){return e("div",{key:o,staticClass:"icon"},[e("a",{staticStyle:{display:"block"},attrs:{href:n.href}},[e("font-awesome-icon",{staticClass:"icon",style:{color:n.hovTheme,backgroundColor:n.bgC},attrs:{icon:n.icon},on:{mouseenter:()=>t.setColor(n),mouseleave:()=>t.resetColor(n)}})],1)])})),0)],2)},b=[];let _=class extends s["c"]{constructor(){super(...arguments),this.icons=[{hovTheme:"#000",icon:["fab","github"],href:"https://github.com/lin-nie",theme:"rgb(255, 0, 0)"},{hovTheme:"#000",icon:["fab","google"],href:"https://scholar.google.com/citations?hl=en&user=3sybTOUAAAAJ",theme:"rgb(67, 135, 246)"},{hovTheme:"#000",icon:["fab","linkedin"],href:"https://www.linkedin.com/in/nie-lin/",theme:"rgb(0, 127, 178)"},{hovTheme:"#000",icon:["fab","twitter-square"],href:"https://twitter.com/NieLin6",theme:"rgb(29, 155, 240)"}]}created(){}get longInfoList(){return[{icon:["fas","home"],msg:this.words.address}]}get shortInfoList(){return[{icon:["fas","envelope"],msg:this.words.email},{icon:["fas","phone-alt"],msg:this.words.phone},{icon:["fas","tv"],msg:this.words.web}]}setColor(t){t.hovTheme=t.theme}resetColor(t){t.hovTheme="#000",t.bgC="#fff"}};Object(a["a"])([Object(h["a"])("words")],_.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],_.prototype,"dictionary",void 0),_=Object(a["a"])([s["a"]],_);var v=_,y=v,C=(n("0aa0"),Object(u["a"])(y,w,b,!1,null,"a7b7cca0",null)),j=C.exports,S=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"profile-wrapper"},[e("div",{staticClass:"profile-info-wrapper"},[t._m(0),e("div",{staticClass:"profile"},[e("h1",{staticClass:"name"},[t._v(" "+t._s(t.words.name)+" ")]),e("p",{staticClass:"advance-line"},[t._v(" "+t._s(t.words.degree)+" ")]),e("p",{staticClass:"advance-line"},[t._v(" "+t._s(t.words.major)+" ")]),e("p",{staticClass:"advance-line"},[t._v(" "+t._s(t.words.department)+" ")]),e("p",{staticClass:"advance-line"},[t._v(" "+t._s(t.words.university)+" ")]),e("hr",{staticStyle:{"margin-top":"5px"}}),e("div",{staticClass:"introduction"},[e("ul",{staticClass:"content"},[e("p",{domProps:{innerHTML:t._s(t.words.personalIntroduction)}})])])])]),e("div",{staticClass:"address-wrapper"}),t._m(1)])},P=[function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"profile-image"},[e("img",{attrs:{src:n("f5f6")}})])},function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"info-wrapper"},[e("div",{staticClass:"infos"}),e("div",{staticClass:"icons"})])}];let x=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],x.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],x.prototype,"dictionary",void 0),x=Object(a["a"])([s["a"]],x);var T=x,N=T,I=(n("2643"),Object(u["a"])(N,S,P,!1,null,"25968870",null)),O=I.exports,k=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"navigation-wrapper"},[e("ul",[e("p",{staticClass:"name"},[t._v(t._s(t.words.navigation.name))]),t._l(t.words.navigation.address,(function(n,o){return e("li",[e("a",{staticClass:"menu-item",attrs:{href:"#"+t.href[o]}},[t._v(t._s(n))])])}))],2)])},U=[];let L=class extends s["c"]{constructor(){super(...arguments),this.href=["Home","New","Research Interest","Publication","Projects","Biography","Professional Experience","Honors","Patent","Software Copyrght","Fund Participation"]}get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],L.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],L.prototype,"dictionary",void 0),L=Object(a["a"])([s["a"]],L);var H=L,A=H,E=(n("0cad"),Object(u["a"])(A,k,U,!1,null,"5a767f6d",null)),M=E.exports,R=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"new-wrapper wrapper-style href",attrs:{id:"New"}},[e("div",[e("section",{staticClass:"title"},[e("h2",[t._v(" "+t._s(t.words.newTitle)+" ")])])]),e("ul",{staticClass:"show-list"},[e("li",{domProps:{innerHTML:t._s(t.words.new.new20)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new19)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new18)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new17)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new16)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new15)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new14)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new13)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new12)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new11)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new10)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new9)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new8)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new7)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new6)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new5)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new4)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new3)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new2)}}),e("li",{domProps:{innerHTML:t._s(t.words.new.new1)}})])])},z=[];let V=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],V.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],V.prototype,"dictionary",void 0),V=Object(a["a"])([s["a"]],V);var F=V,D=F,G=(n("a69c"),Object(u["a"])(D,R,z,!1,null,null,null)),K=G.exports,B=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"research-wrapper wrapper-style href",attrs:{id:"Research Interest"}},[e("div",[e("section",{staticClass:"title"},[e("h2",[t._v(" "+t._s(t.words.researchTitle)+" ")])])]),e("ul",{staticClass:"research-content"},[e("Strong",[t._v(t._s(t.words.overallField))]),e("br"),t._l(t.words.researchOverInterest,(function(n){return e("li",[t._v(" "+t._s(n)+" ")])})),e("br"),e("Strong",[t._v(t._s(t.words.specialField))]),e("br"),t._l(t.words.researchSpecialInterest,(function(n){return e("li",[t._v(" "+t._s(n)+" ")])}))],2)])},W=[];let Q=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],Q.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],Q.prototype,"dictionary",void 0),Q=Object(a["a"])([s["a"]],Q);var Z=Q,Y=Z,J=(n("8c41"),Object(u["a"])(Y,B,W,!1,null,"f0a999b6",null)),X=J.exports,$=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"projects-wrapper wrapper-style href",attrs:{id:"Publication"}},[e("div",[e("section",{staticClass:"title"},[e("h2",[t._v(" "+t._s(t.words.conferenceTitle)+" ")])])]),e("div",t._l(t.words.conferencePublication,(function(o,r){return e("div",{staticClass:"project-component"},[e("div",{staticClass:"projects-img"},[e("a",{attrs:{href:"javascript:;"}},[e("img",{attrs:{src:n("e466")(`./${r}.png`),alt:""}})])]),e("div",{staticClass:"content"},[e("strong",[t._v(t._s(o.name))]),e("img",{attrs:{src:"http://www.linnie.com.cn/img/new.gif"}}),e("p",{domProps:{innerHTML:t._s(o.author)}}),e("p",[t._v(t._s(o.match))]),e("p",[t._v(t._s(o.match2))]),0==r?e("div",[e("a",{attrs:{href:"https://arxiv.org/abs/2207.03095"}},[t._v(t._s(o.paper))]),e("a",{attrs:{href:"http://www.linnie.com.cn/projects/uda_action/"}},[t._v(t._s(o.projectPage))]),e("a",{attrs:{href:"https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA"}},[t._v(t._s(o.code))]),e("a",{attrs:{href:"https://www.youtube.com/watch?v=BnVhNeUBau4"}},[t._v(t._s(o.video))])]):t._e(),1==r?e("div",[e("a",{attrs:{href:"https://arxiv.org/abs/2207.05409"}},[t._v(t._s(o.paper))]),e("a",{attrs:{href:"https://github.com/dzy3/KCD"}},[t._v(t._s(o.code))])]):t._e(),t._l(o.label,(function(n){return e("span",{staticClass:"label"},[t._v(t._s(n))])}))],2)])})),0)])},q=[];let tt=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],tt.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],tt.prototype,"dictionary",void 0),tt=Object(a["a"])([s["a"]],tt);var et=tt,nt=et,ot=(n("d268"),Object(u["a"])(nt,$,q,!1,null,"2c8f5f8c",null)),rt=ot.exports,it=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"projects-wrapper wrapper-style href",attrs:{id:"Projects"}},[e("div",[e("section",{staticClass:"title"},[e("h2",[t._v(" "+t._s(t.words.projectsTitle)+" ")])])]),e("h4",[e("span",{staticStyle:{"background-color":"#ffffd0"}},[t._v(t._s(t.words.projectsHightLight))]),t._v(t._s(t.words.projectsNote)+" ")]),e("div",{staticStyle:{background:"#ffffd0"}},t._l(t.words.recentlyProjects,(function(o,r){return e("div",{staticClass:"project-component"},[e("div",{staticClass:"projects-img"},[e("a",{attrs:{href:"javascript:;"}},[e("img",{attrs:{src:n("d4d5")(`./${r}.gif`),alt:""}})])]),e("div",{staticClass:"content"},[e("strong",[t._v(t._s(o.name))]),e("p",{domProps:{innerHTML:t._s(o.author)}}),e("p",[t._v(t._s(o.match))]),e("p",[t._v(t._s(o.match2))]),0==r?e("div",[e("a",{attrs:{href:"http://www.linnie.com.cn/documents/NieLin_HNU_UTokyo_EgoV_Research_Proposal.pdf"}},[t._v(t._s(o.paper))]),e("a",{attrs:{href:"http://www.linnie.com.cn/projects/egov/"}},[t._v(t._s(o.projectPage))]),e("a",{attrs:{href:"http://www.linnie.com.cn/projects/egov/"}},[t._v(t._s(o.code))]),e("a",{attrs:{href:"http://www.linnie.com.cn/projects/egov/videos/egov_4k.mp4"}},[t._v(t._s(o.video))])]):t._e(),1==r?e("div",[e("a",{attrs:{href:"https://arxiv.org/pdf/2207.03095.pdf"}},[t._v(t._s(o.paper))]),e("a",{attrs:{href:"http://www.linnie.com.cn/projects/uda_action/"}},[t._v(t._s(o.projectPage))]),e("a",{attrs:{href:"https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA"}},[t._v(t._s(o.code))]),e("a",{attrs:{href:"https://www.youtube.com/watch?v=BnVhNeUBau4"}},[t._v(t._s(o.video))]),e("a",{attrs:{href:"./img/cvpr_2022_meeting_photo1.png"}},[t._v(t._s(o.photo))])]):t._e(),2==r?e("div",[e("a",{attrs:{href:"https://arxiv.org/abs/2207.05409"}},[t._v(t._s(o.paper))]),e("a",{attrs:{href:"https://github.com/dzy3/KCD"}},[t._v(t._s(o.code))])]):t._e(),3==r?e("div",[t._v(" "+t._s(o.video)+" ")]):t._e(),t._l(o.label,(function(n){return e("span",{staticClass:"label"},[t._v(t._s(n))])}))],2)])})),0),t._l(t.words.pastProjects,(function(o,r){return e("div",{staticClass:"project-component"},[e("div",{staticClass:"projects-img"},[e("a",{attrs:{href:"javascript:;"}},[e("img",{attrs:{src:n("3a96")(`./${r}.png`),alt:""}})])]),e("div",{staticClass:"content"},[e("strong",[t._v(t._s(o.name))]),e("p",{domProps:{innerHTML:t._s(o.author)}}),e("p",[t._v(t._s(o.match))]),e("p",[t._v(t._s(o.match2))]),0==r?e("div",[e("a",{attrs:{href:"https://ieeexplore.ieee.org/document/9689024"}},[t._v(t._s(o.paper))]),t._v(" "+t._s(o.projectPage)+" "+t._s(o.code)+" "+t._s(o.video)+" "),e("a",{attrs:{href:"./img/ieee_icsip_meeting_photo.png"}},[t._v(t._s(o.photo))])]):t._e(),t._l(o.label,(function(n){return e("span",{staticClass:"label"},[t._v(t._s(n))])}))],2)])}))],2)},at=[];let st=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],st.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],st.prototype,"dictionary",void 0),st=Object(a["a"])([s["a"]],st);var ct=st,pt=ct,ht=(n("6e86"),Object(u["a"])(pt,it,at,!1,null,"69d1cbca",null)),gt=ht.exports,lt=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"biography-wrapper wrapper-style"},[e("div",[e("section",{staticClass:"title"},[e("h2",{staticClass:"href",attrs:{id:"Biography"}},[t._v(" "+t._s(t.words.biographyTitle)+" ")])])]),e("div",[e("p",{staticClass:"biography-content"},[t._v(" "+t._s(t.words.biography.bio1.introduce)+" "),e("a",{attrs:{href:"https://cai-mj.github.io/"}},[t._v(t._s(t.words.biography.bio1.mentor))]),e("br"),t._v(" "+t._s(t.words.biography.bio1.brief1)),e("br"),e("strong",[t._v(t._s(t.words.biography.bio1.brief2))])])])])},dt=[];let ut=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],ut.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],ut.prototype,"dictionary",void 0),ut=Object(a["a"])([s["a"]],ut);var ft=ut,mt=ft,wt=(n("331a"),Object(u["a"])(mt,lt,dt,!1,null,"76d1ccca",null)),bt=wt.exports,_t=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"experience-wrapper wrapper-style href",attrs:{id:"Professional Experience"}},[e("div",[e("section",{staticClass:"title"},[e("h2",[t._v(" "+t._s(t.words.exchangeTitle)+" ")])])]),e("div",{staticClass:"subtitle"},[e("strong",[t._v(t._s(t.words.exchangeSubtitle))])]),e("div",{staticClass:"img-box"},t._l(t.words.exchange,(function(o){return e("div",{staticClass:"exchange-img"},[e("img",{attrs:{src:n("22e7")(`./${o.imgName}.jpg`),alt:""}}),e("a",{attrs:{href:o.href}},[e("div",{staticClass:"mask-desc"},[e("div",{staticClass:"mask-content",domProps:{innerHTML:t._s(o.intro)}})])])])})),0),e("br"),e("div",[e("ul",t._l(t.words.profExprience,(function(n){return e("li",[e("strong",[t._v(t._s(n.name))]),e("br"),t._v(" "+t._s(n.workplace)),e("span",{domProps:{innerHTML:t._s("              ")}}),t._v(t._s(n.topic)),e("br"),t._v(" "+t._s(n.title)+","+t._s(n.supervisor)+" ")])})),0)])])},vt=[];let yt=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],yt.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],yt.prototype,"dictionary",void 0),yt=Object(a["a"])([s["a"]],yt);var Ct=yt,jt=Ct,St=(n("5d3f"),Object(u["a"])(jt,_t,vt,!1,null,"19165cb6",null)),Pt=St.exports,xt=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"awards-wrapper wrapper-style href",attrs:{id:"Honors"}},[e("div",[e("section",{staticClass:"title"},[e("h2",[t._v(" "+t._s(t.words.awardsTitle)+" ")])])]),t._l(t.words.awards,(function(n){return e("ul",{staticClass:"awards-content"},[e("p",[t._v(t._s(t.words.scholarship))]),e("a",{attrs:{href:"http://www.moe.gov.cn/jyb_xxgk/s5743/s5744/A05/202112/t20211216_587869.html"}},[t._v(t._s(t.words.scholar1))]),t._v("   "+t._s(t.words.scholar1explain)),e("br"),e("i",[t._v(t._s(t.words.scholar1supp))]),e("br"),t._v(" "+t._s(t.words.scholar2)),e("br"),t._v(" "+t._s(t.words.scholar3)),e("br"),t._v(" "+t._s(t.words.scholar4)),e("br"),t._v(" "+t._s(t.words.scholar5)),e("br"),t._v(" "+t._s(t.words.scholar6)),e("br"),e("p",[t._v(t._s(n.subtitle))]),t._l(n.content,(function(n){return e("li",[t._v(t._s(n))])}))],2)}))],2)},Tt=[];let Nt=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],Nt.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],Nt.prototype,"dictionary",void 0),Nt=Object(a["a"])([s["a"]],Nt);var It=Nt,Ot=It,kt=(n("9dee"),Object(u["a"])(Ot,xt,Tt,!1,null,"60aafcf6",null)),Ut=kt.exports,Lt=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"publication"},[e("div",{staticClass:"patent-wrapper wrapper-style href",attrs:{id:"Patent"}},[e("div",[e("section",{staticClass:"title"},[e("h2",[t._v(" "+t._s(t.words.patentTitle)+" ")])])]),e("ul",{staticClass:"content"},t._l(t.words.patent,(function(n){return e("li",[e("strong",[t._v(t._s(n.name))]),e("p",{domProps:{innerHTML:t._s(n.author)}}),e("p",{domProps:{innerHTML:t._s(n.number)}})])})),0)])])},Ht=[];let At=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],At.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],At.prototype,"dictionary",void 0),At=Object(a["a"])([s["a"]],At);var Et=At,Mt=Et,Rt=(n("1dd2"),Object(u["a"])(Mt,Lt,Ht,!1,null,"4b1834b5",null)),zt=Rt.exports,Vt=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"copyrght-wrapper wrapper-style href",attrs:{id:"Software Copyrght"}},[e("div",[e("section",{staticClass:"title"},[e("h2",[t._v(" "+t._s(t.words.copyrghtTitle)+" ")])])]),e("ul",{staticClass:"copyrght-content"},t._l(t.words.softwareCopyrght,(function(n){return e("li",[e("strong",[t._v(t._s(n.name))]),e("p",{domProps:{innerHTML:t._s(n.Number)}})])})),0)])},Ft=[];let Dt=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],Dt.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],Dt.prototype,"dictionary",void 0),Dt=Object(a["a"])([s["a"]],Dt);var Gt=Dt,Kt=Gt,Bt=(n("3c15"),Object(u["a"])(Kt,Vt,Ft,!1,null,"47db2168",null)),Wt=Bt.exports,Qt=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"tutorial-wrapper wrapper-style href",attrs:{id:"Fund Participation"}},[e("div",[e("section",{staticClass:"title"},[e("h2",[t._v(" "+t._s(t.words.scientificFundTitle)+" ")])])]),e("ul",{staticClass:"content"},t._l(t.words.scientificFund,(function(n){return e("li",[e("strong",{domProps:{innerHTML:t._s(n.name)}}),e("p",{domProps:{innerHTML:t._s(n.match)}})])})),0)])},Zt=[];let Yt=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],Yt.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],Yt.prototype,"dictionary",void 0),Yt=Object(a["a"])([s["a"]],Yt);var Jt=Yt,Xt=Jt,$t=(n("9591"),Object(u["a"])(Xt,Qt,Zt,!1,null,"429e83f7",null)),qt=$t.exports,te=function(){var t=this,e=t._self._c;t._self._setupProxy;return e("div",{staticClass:"footer-wrapper wrapper-style"},[e("p",[t._v(t._s(t.words.footer.period))]),e("p",{staticClass:"update"},[e("strong",[t._v(t._s(t.words.footer.lastUpdated))])])])},ee=[];let ne=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(t=>this.dictionary[t].__identity)}};Object(a["a"])([Object(h["a"])("words")],ne.prototype,"words",void 0),Object(a["a"])([Object(h["b"])("dictionary")],ne.prototype,"dictionary",void 0),ne=Object(a["a"])([s["a"]],ne);var oe=ne,re=oe,ie=(n("071d"),Object(u["a"])(re,te,ee,!1,null,"c0cae402",null)),ae=ie.exports;let se=class extends s["c"]{};se=Object(a["a"])([Object(s["a"])({components:{Header:m,Profile:O,InfoList:j,NavigationBar:M,New:K,ResearchInterest:X,Publication:rt,Projects:gt,Biography:bt,ProfessionalExperience:Pt,Honors:Ut,Patent:zt,SoftwareCopyrght:Wt,ScientificFund:qt,Footer:ae}})],se);var ce=se,pe=ce,he=(n("fbd7"),Object(u["a"])(pe,r,i,!1,null,null,null)),ge=he.exports,le=n("2f62");const de={__identity:"English",__langKey:"en",name:"Nie (Elon) Lin",degree:"Master Student (M2)",major:"Interdisciplinary Information Studies",department:"Graduate School of Interdisciplinary Information Studies (GSII)",university:"The University of Tokyo (UTokyo)",personalIntroduction:"Hi, I am a second-year CS Master Student (M2) at \n  <a href='https://www.u-tokyo.ac.jp/en/' target=\"_blank\">The University of Tokyo</a>\n  , supervised by Prof. \n  <a href='https://sites.google.com/ut-vision.org/ysato/' target=\"_blank\">Yoichi Sato</a>\n   and work as a member of <a href='https://www.ut-vision.org/' target=\"_blank\">Computer Vision Group</a>\n   at <a href='https://www.iis.u-tokyo.ac.jp/en/' target=\"_blank\">Institute of Industrial Science (IIS)</a>\n  I received my bachelor’s degree of software engineering in 2022, supervised by Prof. \n  <a href='https://cai-mj.github.io/' target=\"_blank\">Minjie Cai</a>\n  . Now I am a research intern at \n  <a href='https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/' target=\"_blank\">Microsoft Research Aisa</a>\n  , supervised by Dr. \n  <a href='https://recmind.cn/' target=\"_blank\">Dongsheng Li</a>, and work with Dr. \n  <a href='https://victorywys.github.io/' target=\"_blank\">Yansen Wang</a>\n   & Dr. \n  <a href='https://frosthan.github.io/' target=\"_blank\">Dongqi Han</a>\n   in <a href='https://www.microsoft.com/en-us/research/group/shanghai-ai-ml-group/' target=\"_blank\">Shanghai AI/ML Group</a>.",address:"Address: Institute of Industrial Science (IIS), The University of Tokyo, 4-6-1 Komaba, Meguro-ku, Tokyo, 153-8505 JAPAN",email:"Email: nielin@iis.u-tokyo.ac.jp",phone:"Phone: +81 080-5637-8886",web:"Web: lin-nie.github.io",navigation:{name:"Nie Lin",address:["Home","News","Research Interests","Publications","Projects","Biography","Professional Experience","Honors","Patents","Software Copyright","Fund Participation"]},newTitle:"News",new:{new1:"[ 2019.08 ] Under the leadership of Prof. Lvy Wang, I completed a research project on mathematics and machine learning in <Strong>University of Toronto, Canada</Strong>. Lay a mathematical foundation for my future research in <Strong>Computer Vision</Strong>.",new2:"[ 2019.12 ] I won 2019 year's <Strong>The First Prize Scholarship</Strong> for being the first in my grade. Thanks!",new3:"[ 2020.03 ] During the winter vacation, I worked as a research intern under the guidance of Prof. Qing Liao from <Strong>Harbin Institute of Technology (HIT)</Strong> to complete the project of <Strong>video understanding and analysis</Strong> through deep learning.",new4:"[ 2020.08 ] I completed my exchange programme study in the field of <Strong>Artificial Intelligence and Deep Learning</Strong> in the <Strong>National University of Singapore</Strong>. And won the <Strong>Honorary Award of the National University of Singapore</Strong>.",new5:"[ 2020.09 ] Congratulations, I successfully joined the <Strong>Institute of Industrial Artificial Intelligence Technology (IIAIT)</Strong> in Songshan Lake, Dongguan through multiple selection, and was supervised by <Strong>Prof. Gao Chen from Tsinghua University</Strong>.",new6:"[ 2020.10 ] I got The Third prize of <Strong>China Artificial Intelligence Electronic Design Competition</Strong>. Congratulations !!",new7:"[ 2020.12 ] I won 2020 year's <Strong>The First Prize Scholarship</Strong> and <Strong>The Kao Wei-kwong Enterprise Scholarship (Outstanding Engineering Representative) </Strong> for being the first in my grade. Thanks!",new8:"[ 2021.01 ] Our team successfully entered the <a href='https://www.ccf.org.cn/en/'>China Computer Federation (CCF) </a> <Strong>Artificial Intelligence Vision Algorithm Competition</Strong> and final with the rank of <Strong>13/2207</Strong>. A great team work experience !!",new9:"[ 2021.05 ] I won the <Strong>international second prize</Strong> in the American Mathematical Contest In Modeling (USA MCM).",new10:"[ 2021.06 ] Started research working as a <Strong>Research Assistant</Strong> at Computer Vision Lab, Hunan University. <br>Supervised by Prof. <a href='https://cai-mj.github.io/'>Minjie Cai</a>.<a href=\"https://www.linnie.com.cn/documents/Research_Assistant_Minjie_Cai_Hunan_University.pdf\">[Research Certificate]</a>",new11:"[ 2021.10 ] I got my own <Strong>head-mounted camera</Strong> from our laboratory and will be trying to collect the first-person dataset in the future. Thanks!",new12:"[ 2021.12 ] I won 2021 year's <Strong>The First Prize Scholarship</Strong> and <Strong>The Lingnan Academic Scholarship (Outstanding Academic Representative) </Strong> for being the first in my grade. Thanks!",new13:"[ 2022.05 ] Congratulations! I won the <a href='http://www.moe.gov.cn/jyb_xxgk/s5743/s5744/A05/202112/t20211216_587869.html'>National Scholarship of the People's Republic of China</a>, issued by the <a href='http://en.moe.gov.cn/'>Ministry of Education of China</a>, which is the highest level scholarship program in China! (<Strong>TOP 0.01% Students in China</Strong>).",new14:'[ 2022.06 ] My graduation thesis <Strong>"First-person Action Recognition Based on Unsupervised Domain Adaptation in Egocentric Video"</Strong> successfully pass the thesis defense of undergraduate graduation design.',new15:"[ 2022.06 ] Congratulations! I successfully graduated from <Strong>DGUT Computer Software Engineering</Strong> with <strong>the first place</strong> in my major (<strong>Rank 1st / 78</strong> ) with a <Strong>Bachelor of Engineering degree</Strong>. And won the <Strong>Outstanding Undergraduate Graduate</Strong>",new16:'[ 2022.06 ] Congratulations! My paper on <a href="https://eyewear-computing.org/EPIC_CVPR22/">CVPR-EPIC 2022</a> about <Strong>UDA Frist-person Action Recognition</Strong> has been successfully accepted, under the supervision of Prof. <a href="https://cai-mj.github.io/">Minjie Cai</a>. The arXiv and code is available. <a href="https://arxiv.org/abs/2207.03095">[ArXiv]</a> <a href="https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA">[Github Code]</a>',new17:'[ 2022.07 ] I was invited to attend this year\'s <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a> and participate in the <a href="https://eyewear-computing.org/EPIC_CVPR22/">EPIC 2022</a> presentation. <br><a href="./img/cvpr_2022_meeting_photo1.png">[Meeting Photo1]&<a><a href="./img/cvpr_2022_meeting_photo2.png">[Meeting Photo2]&<a><a href="./img/cvpr_2022_meeting_photo3.png">[Meeting Photo3]&<a><a href="./img/cvpr_2022_meeting_photo4.png">[Meeting Photo4]&<a><a href="./img/cvpr_2022_meeting_photo5.png">[Meeting Photo5]&<a><a href="./img/cvpr_2022_meeting_photo6.png">[Meeting Photo6]<a>',new18:'[ 2022.07 ] Our paper on <Strong>Knowledge Transfer Learning</Strong> has been accepted for <Strong>ECCV 2022</Strong>!! Paper and code is available. <br><a href="https://arxiv.org/pdf/2207.05409.pdf">[Paper]</a><a href="https://arxiv.org/abs/2207.05409">[Arxiv]</a><a href="https://github.com/dzy3/KCD">[Github Code]</a>',new19:'[ 2022.08 ] Under the guidance of Prof. <a href="https://cai-mj.github.io/">Minjie Cai</a>, I submitted a paper at <Strong>BMVC 2022</Strong> this year based on <Strong>hand regions in egocentric videos related to first-personaction recognition</Strong>. Code will be open source !!',new20:'[ 2022.09 ] I really hope that I can apply for a research student and master as soon as possible to start my new project: <Strong>EgoV: From Virtual to Real </Strong>. <a href="http://www.linnie.com.cn/projects/egov/">[Project Page]</a><a href="http://www.linnie.com.cn/documents/NieLin_HNU_UTokyo_EgoV_Research_Proposal.pdf">[Research Proposal]</a>'},biographyTitle:"Biography",biography:{bio1:{introduce:"(2021.6 - Now) Research Assistant. Supervised by Prof.",mentor:"Minjie Cai",brief1:"College of Computer Science and Electronic Engineering, Computer Vision Lab",brief2:"Hunan University"}},exchangeTitle:"Professional Experience",exchangeSubtitle:"I am very keen on scientific research exchange，the following are the Universities where I often communicate and study :",exchange:[{imgName:"清华大学",href:"https://www.tsinghua.edu.cn/en/",intro:'<p style="font-size: 20px">\n              Tsinghua University\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: No.17 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : No.28 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: No.20 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              ARWU 2021: No.29 in the world University Rankings\n              </p>\n               '},{imgName:"NUS",href:"https://www.nus.edu.sg/",intro:'<p style="font-size: 20px">\n              National University of Singapore\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: No.11 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : No.32 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: No.25 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n\n              </p>\n      '},{imgName:"TORONTO",href:"https://www.utoronto.ca/",intro:'<p style="font-size: 20px">\n              University of Toronto\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: No.26 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : No.17 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: No.18 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              ARWU 2021: No.23 in the world University Rankings\n              </p>\n      '},{imgName:"香港科技大学",href:"https://hkust.edu.hk/",intro:'\n              <p style="font-size: 20px">\n              Hong Kong University of Science and Technology\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: No.34 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : No.109 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: No.56 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n           \n              </p>\n      '}],profExprience:[{name:"1. Hunan University (HNU)",workplace:"Changsha, China",topic:"Topic: First-person Action Recognition base on Hand Region",title:"Research Assistant",supervisor:" Supervisor: Prof. Minjie Cai [Hunan University]"},{name:"2. Institute of Industrial Artificial Intelligence Technology (IIAIT)",workplace:"Dongguan, China",topic:"Topic: Digital Image Processing",title:"Research Assistant",supervisor:" Supervisor: Prof. Gao Chen [Tsinghua University]"},{name:"3. Harbin Institute of Technology (HIT)",workplace:"Shenzhen, China",topic:"Topic: Video Analysis and Understanding",title:"Research Intern",supervisor:" Supervisor: Prof. Qing Liao [Harbin Institute of Technology]"},{name:"4. University of Toronto (UofT)",workplace:"Toronto, Canada",topic:"Topic: Mathematics and Machine Learning",title:"Project Student",supervisor:" Supervisor: Prof. Lvy Wang [University of Toronto]"}],researchTitle:"Research Interests",overallField:"Overall Field",researchOverInterest:["Computer Vision (CV)","First-person Vision (FPV)","Human-computer Interactions (HCI)"],specialField:"Special Interests",researchSpecialInterest:["1. Egocentric Video Understanding and Analysis","2. Action Recognition","3. Hand Region Analysis","4. Domain Adaptation & Generalization","5. Knowledge Transfer Learning",".........................."],awardsTitle:"Honors",scholarship:"Scholarship",scholar1:"1. National Scholarship of the People's Republic of China",scholar1explain:"[Ministry of Education of China]",scholar1supp:"(TOP 0.1% Students in China)",scholar2:"2. The Lingnan Academic Scholarship  [Outstanding Academic Representative]",scholar3:"3. The First Prize Scholarship   [The First Place of GPA in the Grade, 2021]",scholar4:"4. The Kao Wei-kwong Enterprise Scholarship   [Outstanding Engineering Representative]",scholar5:"5. The First Prize Scholarship   [The First Place of GPA in the Grade, 2020]",scholar6:"6. The First Prize Scholarship   [The First Place of GPA in the Grade, 2019]",awards:[{subtitle:"Awards",content:["Outstanding Undergraduate of Guangdong Province","Outstanding Undergraduate's Thesis","International Second Prize in the American Mathematical Contest In Modeling","China Computer Federation AI Vision Algorithm Competition (Rank 13/2207)","The Third prize of China Artificial Intelligence Electronic Design Competition","Honorary Award of the National University of Singapore","Excellent Huawei Developer Award"]}],conferenceTitle:"Publications",conferencePublication:[{name:"EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022 Technical Report",author:"<Strong>Nie Lin</Strong>, <a href='https://cai-mj.github.io/' target=\"_blank\">Minjie Cai</a><sup>✉</sup>",match:"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR-EPIC), 2022",match2:"",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"Knowledge Condensation Distillation",author:"Chenxin Li, <a href='https://lmbxmu.github.io/'>Mingbao Lin</a>, Zhiyuan Ding, <Strong>Nie Lin</Strong>, Yihong Zhuang, <a href='https://huangyue05.github.io/'>Yue Huang</a><sup>✉</sup>,...",match:"European Conference on Computer Vision (ECCV), 2022",match2:"",paper:"[Paper]",projectPage:"",code:"[Github Code]",video:""}],journalTitle:"Journal Publication",journalPublication:[{}],patentTitle:"Patents",patent:[{name:"Human-computer Interaction (HCI) Sensing Devices based on Analog Signal Processing",author:'<a href="">Nie Lin</a>, Chanzhi Liu, Haofeng Li, Shihao Zou, Junyu Li, Ruofan Hu',number:"CN 202022246705.5"}],copyrghtTitle:"Software Copyright",softwareCopyrght:[{name:"OCR Recognition System for Japanese Postal Payment Notes",Number:"No.A0003976 in SoftwareCopyright"},{name:"Video copyright protection system based on artificial intelligence",Number:"No.4840268 in SoftwareCopyright"}],projectsTitle:"Projects",projectsHightLight:"Highlighted",projectsNote:" projects are recently projects.",recentlyProjects:[{name:"EgoV: A New Datasets of Egocentric Videos Across Real and Virtual",author:"<strong>!! As a new long-term research project will be carried out at my master's level !!</strong>",match:"",match2:"",paper:"[Research Proposal]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"UDA First-person Action Recognition based on Hand Regions in Egocentric Videos",author:"<strong>Nie Lin</strong>, Minjie Cai",match:"Hunan University",match2:"",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]",photo:"[Meeting Photo]"},{name:"Knowledge Condensation Distillation base on Transfer Learning",author:"Chenxin Li, Mingbao Lin, <strong>Nie Lin</strong>, Yihong Zhuang, Yue Huang",match:"Xiamen & Hunan University, Tencent Youtu Lab",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"Dataset Acquisition from First-person Perspective (Through Head-mounted Camera)",author:"<strong>Nie Lin</strong>",match:"Hunan University",paper:"",projectPage:"",code:"",video:""}],pastProjects:[{name:"Multi-Modal Video Analysis and Understanding",author:"<strong>Nie Lin</strong>, Fan Guo, Jie Wang, Ye Ding, Qing Liao",match:"Harbin Institute of Technology (HIT) ",match2:"",paper:"",projectPage:"",code:"",video:"[video]"},{name:"Hand-ball Action Recognition Control System based on OpenMV Machine Vision",author:"<strong>Nie Lin</strong>, Bing Wang, Qingfeng Zhou",match:"China Artificial Intelligence Electronic Design Competition",match2:"",paper:"",projectPage:"",code:"",video:""}],scientificFundTitle:"Fund Participation",scientificFund:[{name:'<a href="https://www.nsfc.gov.cn/english/site_1/index.html">The National Natural Science Foundation of China</a>',match:"No. 61971138 in the Scientific Fund"},{name:"Basic and Applied Basic Research Project of Guangdong Province under Grant",match:"No. 2019A1515111149 in the Scientific Fund"},{name:"Guangdong Higher Education Innovation and College Development Project",match:"No. 2020ZDZX3047 in the Scientific Fund"}],footer:{period:"© 2018 - 2025   Nie Lin",lastUpdated:"Last updated: February 10,2025"}};var ue=de;const fe={__identity:"日本語",__langKey:"jp",name:"林 涅（リン ネ）",degree:"修士 (M2)",major:"学際情報学",department:"学際情報学府",university:"東京大学",personalIntroduction:"こんにちは、私は\n  <a href='https://www.u-tokyo.ac.jp/ja/index.html' target=\"_blank\">東京大学</a>\n  の学際情報学専攻の修士2年生です。\n  <a href='https://sites.google.com/ut-vision.org/ysato/' target=\"_blank\">佐藤洋一</a>\n  教授の指導の下、\n  <a href='https://www.iis.u-tokyo.ac.jp/ja/' target=\"_blank\">生産技術研究所 (IIS)</a>\n  の\n  <a href='https://www.ut-vision.org/ja/' target=\"_blank\">コンピュータビジョングループ</a>\n  の一員として研究を行っています。2022年にソフトウェア工学の学士号を取得し、その間、\n  <a href='https://cai-mj.github.io/' target=\"_blank\">蔡敏捷</a>\n  教授の指導を受けました。現在、私は\n  <a href='https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/' target=\"_blank\">マイクロソフトアジア研究院</a>\n  でインターンシップを行っており、\n  <a href='https://recmind.cn/' target=\"_blank\">李東勝</a>\n  博士の指導の下、\n  <a href='https://victorywys.github.io/' target=\"_blank\">王延森</a>\n  博士と\n  <a href='https://frosthan.github.io/' target=\"_blank\">韓東起</a>\n  博士と共に\n  <a href='https://www.microsoft.com/en-us/research/group/shanghai-ai-ml-group/' target=\"_blank\">Shanghai AI/ML Group</a>で研究しています。\n  ",address:"アドレス: 〒 153-8505 東京都目黒区駒場 4-6-1 東京大学 生産技術研究所",email:"メールアドレス: nielin@iis.u-tokyo.ac.jp",phone:"電話番号: +81 080-5637-8886",web:"ホームページ: lin-nie.github.io",newTitle:"ニュース",navigation:{name:"リン ネエ",address:["ホームページ","ニュース","研究趣味","発表論文","プロジェクト","バイオグラフィー","専門経験","奨学金・受賞","発明特许","ソフトウエア著作権","研究ファンド"]},new:{new1:"[ 2019.08 ] Prof. Lvy Wangのご指導により、<strong>カナダのトロント大学（UofT）</strong>で私は数学と機械学習に関する研究プロジェクトを取り組みました。今後の<strong>コンピュータビジョン</strong>に関する研究に数学の基礎を築きくれました。",new2:"[ 2019.12 ] 私は<strong>学年トップ1の成績</strong>で2019年度の<strong>一等奨学金</strong>を受賞しました。ありがとうございます!",new3:"[ 2020.03 ] 二年生の冬休み、<strong>ハルビン工業大学（HIT）</strong>の<strong>Prof. Liao</strong>のご指導により、私は研究実習に参加し、ディープ・ラーニングを用いて<strong>ビデオの理解と分析</strong>に関するプロジェクトを完成しました。",new4:"[ 2020.08 ] 私は<strong>シンガポール国立大学（NUS）</strong>で<strong>人工知能とディープラーニングのプロジェクトスタディ</strong>を修了しました。シンガポール国立大学から<strong>栄誉賞</strong>を受賞しました。",new5:"[ 2020.09 ] 【祝】数回の選抜を経て、私は<strong>工業人工知能技術研究院(IIAIT)</strong>に入選しました。これから<strong>清華大学</strong>陳高先生のご指導により、デジタル画像処理に関する研究を展開します。",new6:"[ 2020.10 ] <Strong>中国人工知能電子デザインコンテスト</Strong>で三等賞を受賞しました !!",new7:"[ 2020.12 ] 私は<strong>学年トップ1の成績</strong>で2020年の<strong>一等奨学金</Strong>及び<Strong>高偉光企業奨学金(傑出工程代表)</strong>を受賞しました。ありがとうございます。",new8:'[ 2021.01 ] うちのチームは13/2207の順位で<a href= "https://www.ccf.org.cn/en/">中国コンピュータ学会（CCF）</a><Strong>人工知能視覚アルゴリズムコンテストの決勝戦</Strong>に入選しました。素晴らしいチームワークでした！！',new9:"[ 2021.05 ] 【祝】アメリカ数学モデリングコンテスト(USA MCM/ICM)で<Strong>国際二等賞</Strong>を受賞しました！",new10:'[ 2021.06 ] 湖南大学のコンピュータビジョン研究室で<strong>アシスタント研究員</strong>として務め始めました。<br>指導先生は<a href="https://cai-mj.github.io/">蔡 敏捷教授</a>です, よろしくお願いします~<a href="https://www.linnie.com.cn/documents/Research_Assistant_Minjie_Cai_Hunan_University.pdf">[研究證明]</a>',new11:"[ 2021.10 ] 研究室から自分の<Strong>ヘッドセット・カメラ</Strong>をゲットしました。これを使って<Strong>一人称データセット</Strong>の収集を試みます。ありがとうございます。",new12:"[ 2021.12 ] 私は<Strong>学年トップ1の成績</Strong>で2021年の<Strong>一等奨学金</Strong>及び<Strong>嶺南学術奨学金(優秀学術代表)</Strong>を獲得しました。ありがとうございます。",new13:"[ 2022.05 ] 【祝】<a href='http://en.moe.gov.cn/'>中華人民共和国教育部</a>から<a href='http://www.moe.gov.cn/jyb_xxgk/s5743/s5744/A05/202112/t20211216_587869.html'>国家レベル奨学金</a>を受賞しました。これは中国最高レベルの奨学金プログラムです。（<Strong>全国上位0.01%の学生</Strong>）.",new14:"[ 2022.06 ] 私の卒業論文<strong>「エゴセントリックビデオにおけるUDA適応に基づく一人称行動認識」</strong>は、無事に答弁に合格しました。",new15:"[ 2022.06 ] 【祝】私は<strong>専攻の第一位(Rank 1st / 78</strong>)として<strong>工学学士</strong>を取得し、順調に<strong>東莞理工コンピュータソフトウェア工程</strong>専攻から卒業しました。そして<strong>優秀卒業生を受賞</strong>しました。",new16:'[ 2022.06 ] 【祝】<a href="https://cai-mj.github.io/">蔡敏捷 先生</a>のご指導のもとで、私の<Strong>無監督ドメイン適応について一人称動作認識</Strong>に関する論文は<a href="https://eyewear-computing.org/EPIC_CVPR22/">CVPR-EPIC 2022</a>に採択されました。論文とコードは利用可能です。<a href="https://arxiv.org/abs/2207.03095">[ArXiv 预印本]</a> <a href="https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA">[Github代码]</a>',new17:'[ 2022.07 ] 私は今年の<a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>に招待されて、<a href="https://eyewear-computing.org/EPIC_CVPR22/">EPIC 2022</a>の講演に参加しました。<br><a href="./img/cvpr_2022_meeting_photo1.png">[会議の写真1]&<a><a href="./img/cvpr_2022_meeting_photo2.png">[会議の写真2]&<a><a href="./img/cvpr_2022_meeting_photo3.png">[会議の写真3]&<a><a href="./img/cvpr_2022_meeting_photo4.png">[会議の写真4]&<a><a href="./img/cvpr_2022_meeting_photo5.png">[会議の写真5]&<a><a href="./img/cvpr_2022_meeting_photo6.png">[会議の写真6]<a>.',new18:'[ 2022.07 ] 私たちのノウレッジ・トランスファー・ラーニングに関する論文はECCV 2022に採択されました。論文とコードは利用可能です。<a href="https://arxiv.org/pdf/2207.05409.pdf">[論文]</a><a href="https://arxiv.org/abs/2207.05409">[Arxiv プリプリント]</a><a href="https://github.com/dzy3/KCD">[Github コード]</a>',new19:'[ 2022.08 ] <a href="https://cai-mj.github.io/">蔡敏捷 先生</a>のご指導のもとで、<strong>BMVC 2022</strong>に<strong>エゴセントリックビデオにおける手の一人称行動認識に関する論文</strong>を提出しました。コードはまもなくオープンソースになります~',new20:'[ 2022.09 ] できるだけ早く日本の大学院に応募して、自分の新たしいプロジェクト「EgoV：バーチャルからリアルへ」を始めたいと思います。<a href="http://www.linnie.com.cn/projects/egov/">[プロジェクト ページ]</a><a href="http://www.linnie.com.cn/documents/NieLin_HNU_UTokyo_EgoV_Research_Proposal.pdf">[研究計画書]</a>'},biographyTitle:"バイオグラフィー",biography:{bio1:{introduce:"(2021.6-現在)  アシスタント研究員. 指導教員は准教授",mentor:"蔡 敏捷",brief1:"情報科学工学部, Computer Vision Lab",brief2:"湖南大學"}},exchangeTitle:"専門経験",exchangeSubtitle:"私は非常に科学研究の交流に熱心です、以下はよく交流して勉強している大学です：",exchange:[{imgName:"清华大学",href:"https://www.tsinghua.edu.cn/en/",intro:'<p style="font-size: 20px">\n              清華大学\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学のランキングーーNo.17\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学のランキングーーNo.28\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学のランキングーーNo.20\n              </p>\n              <br><p style="font-size: 15px">\n              ARWU 2021: 世界大学のランキングーーNo.29\n              </p>\n                '},{imgName:"NUS",href:"https://www.nus.edu.sg/",intro:'<p style="font-size: 20px">\n              シンガポール国立大学（NUS）\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学のランキングーーNo.11\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学のランキングーーNo.32\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学のランキングーーNo.25\n              </p>\n              <br><p style="font-size: 15px">\n\n              </p>\n      '},{imgName:"TORONTO",href:"https://www.utoronto.ca/",intro:'<p style="font-size: 20px">\n              トロント大学（UofT）\n              </p> \n              <br><p style="font-size: 14.9px">\n              QS 2021: 世界大学のランキングーーNo.26\n              </p>\n              <br><p style="font-size: 14.9px">\n              U.S. New : 世界大学のランキングーーNo.17\n              </p>\n              <br><p style="font-size: 14.9px">\n              THE 2021: 世界大学のランキングーーNo.18\n              </p>\n              <br><p style="font-size: 14.9px">\n              ARWU 2021: 世界大学のランキングーーNo.23\n              </p>\n      '},{imgName:"香港科技大学",href:"https://hkust.edu.hk/",intro:'\n              <p style="font-size: 20px">\n              ホンコン科技大学（HKUST）\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学のランキングーーNo.34\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学のランキングーーNo.109\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学のランキングーーNo.56\n              </p>\n              <br><p style="font-size: 15px">\n           \n              </p>\n      '}],profExprience:[{name:"1. 湖南大学 (HNU)",workplace:"長沙, 中国",topic:"研究テーマ: 手部領域に基づく一人称働作認識",title:"アシスタント研究員",supervisor:" 指導教授: 蔡 敏捷 教授 [湖南大学]"},{name:"2. 工业人工智能技术研究所 (IIAIT)",workplace:"东莞, 中国",topic:"研究课题: 数字图像处理",title:"アシスタント研究員",supervisor:" 指导教授: 陈高教授 [清华大学]"},{name:"3. 哈尔滨工业大学 (HIT)",workplace:"深圳, 中国",topic:"研究课题: 视频分析与理解",title:"研究实习生",supervisor:" 指导教授: 廖清教授 [哈尔滨工业大学(深圳)]"},{name:"4. 多伦多大学 (UofT)",workplace:"多伦多, 加拿大",topic:"研究课题: 数学与机器学习",title:"项目学生",supervisor:" 指导教授: Lvy Wang教授 [多伦多大学]"}],researchTitle:"研究趣味",overallField:"Overall Field",researchOverInterest:["コンピュータビジョン (CV)","一人称視覚 (FPV)","ヒューマンコンピュータインタラクション (HCI),"],specialField:"Special Interests",researchSpecialInterest:["1. 自己中心的なビデオ理解と分析","2. 行動認識","3. 手部区域解析","4. ドメイン適応と一般化","5. 知識移動学習",".........................."],awardsTitle:"奨学金・受賞",scholarship:"奨学金",scholar1:"1. 中華人民共和国国家奨学金",scholar1explain:"[中華人民共和国教育部]",scholar1supp:"(中国の上位0.1%の学生)",scholar2:"2. 嶺南学術奨学金  [傑出した学術の代表]",scholar3:"3. 2021年度 一等奨学金   [学年GPA 1位、2021年]",scholar4:"4. 高偉光企業奨学金   [傑出した工事の代表]",scholar5:"5. 2020年度 一等奨学金   [学年GPA 1位、2020年]",scholar6:"6. 2019度 一等奨学金   [学年GPA 1位、2019年]",awards:[{subtitle:"受賞",content:["広東省の優秀な学部卒業生","優秀な学部生の論文","米国数学モデリングコンテスト国際2位","中国コンピュータ学会AI視覚アルゴリズム大会 (順位13/2207)","中国人工知能電子デザインコンテスト3等賞","シンガポール国立大学名誉賞","ファーウェイ優秀開発者賞"]}],conferenceTitle:"発表論文",conferencePublication:[{name:"EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022 Technical Report",author:"<Strong>Nie Lin</Strong>, <a href='https://cai-mj.github.io/' target=\"_blank\">Minjie Cai</a><sup>✉</sup>",match:"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR-EPIC), 2022",match2:"",paper:"[論文]",projectPage:"[プロジェクト ページ]",code:"[コード]",video:"[ビデオ]"},{name:"Knowledge Condensation Distillation",author:"Chenxin Li, <a href='https://lmbxmu.github.io/'>Mingbao Lin</a>, Zhiyuan Ding, <Strong>Nie Lin</Strong>, Yihong Zhuang, <a href='https://huangyue05.github.io/'>Yue Huang</a>*,...",match:"European Conference on Computer Vision (ECCV), 2022",match2:"",paper:"[論文]",projectPage:"",code:"[コード]",video:""}],journalTitle:"ジャーナル論文",journalPublication:[{name:"暂無"}],patentTitle:"発明特许",patent:[{name:"アナログ信号処理ベースのヒューマンインタラクション感知装置",author:'<a href="#">林 涅</a>、劉 嬋梓、黎 浩鋒、鄒 世豪、李 俊裕',number:"CN 202022246705.5"}],copyrghtTitle:"ソフトウエア著作権",softwareCopyrght:[{name:"日本郵便の支払伝票OCR認識システム",Number:"ソフトウエア著作権 No.A0003976"},{name:"人工知能による映像著作権保護システム",Number:"ソフトウエア著作権 No.4840268"}],projectsTitle:"プロジェクト",projectsHightLight:"Highlighted",projectsNote:" は最近取り組んだプロジェクトについて言及した。",recentlyProjects:[{name:"EgoV: リアルとバーチャルの自己中心的なビデオの全く新しいデータセットです",author:"<strong>!! 新しい長期プロジェクトとして修士課程で始めます !!</strong>",match:"",match2:"",paper:"[研究計画書]",projectPage:"[プロジェクト ページ]",code:"[コード]",video:"[ビデオ]"},{name:"自己中心ビデオの手領域に基づく監督のない領域適応一人称動作認識",author:"<strong>林 涅</strong>, 蔡 敏捷",match:"湖南大学",match2:"",paper:"[論文]",projectPage:"[プロジェクト ページ]",code:"[コード]",video:"[ビデオ]",photo:"[会議の写真]"},{name:"移動学習による知識濃縮蒸留",author:"李 宸鑫, 林 明寶, <strong>林 涅</strong>, 莊 毅鴻, 黃 悅",match:"廈門大学 & 湖南大学",paper:"[論文]",projectPage:"[プロジェクト ページ]",code:"[コード]",video:"[ビデオ]"},{name:"一人称視点でのデータ収集 (ヘッドマウントカメラによる)",author:"<strong>林 涅</strong>",match:"湖南大学",paper:"",projectPage:"",code:"",video:""}],pastProjects:[{name:"マルチモダリティ ビデオ分析と理解",author:"<strong>林 涅</strong>, 郭 凡, 王 傑, 丁 燁, 廖 清",match:"ハルビン工業大学 (HIT) ",match2:"",paper:"",projectPage:"",code:"",video:""},{name:"OpenMVマシンビジョンによる ハン-ドボール 動作認識制御システム",author:"<strong>林 涅</strong>, 王 斌, 周 清峰",match:"中国人工知能電子デザインコンテスト",match2:"",paper:"",projectPage:"",code:"",video:""}],scientificFundTitle:"研究ファンド",scientificFund:[{name:'<a href="#">国家自然科学ファンド</a>',match:"国家自然科学ファンド号：No. 61971138"},{name:"広東省基礎と応用基礎研究助成プロジェクト",match:"项目基金号：No. 2019A1515111149"},{name:"広東省高等教育イノベーションと高校発展プロジェクト",match:"工程基金号：No. 2020ZDZX3047"}],footer:{period:"© 2018 - 2022   林涅",lastUpdated:"前回のアップデート: 2025年02月10日"}};var me=fe;const we={__identity:"中文",__langKey:"zh",name:"林 涅",degree:"硕士 (M2)",major:"交叉信息学",department:"跨学科交叉信息学院",university:"东京大学",personalIntroduction:"你好，我是\n  <a href='https://www.u-tokyo.ac.jp/zh/index.html' target=\"_blank\">东京大学</a>\n  跨学科交叉信息学硕士二年级的研究生，在\n  <a href='https://sites.google.com/ut-vision.org/ysato/' target=\"_blank\">佐藤洋一</a>\n  教授的指导下，作为東京大学\n  <a href='https://www.iis.u-tokyo.ac.jp/en/' target=\"_blank\">生産技術研究所 (IIS)</a>\n  —\n  <a href='https://www.ut-vision.org/' target=\"_blank\">计算机视觉小组</a>\n  的成员进行研究。我于2022年获得软件工程学士学位，在此期间接受\n  <a href='https://cai-mj.github.io/' target=\"_blank\">蔡敏捷</a>\n  教授的指导。目前，我在\n  <a href='https://www.microsoft.com/en-us/research/lab/microsoft-research-asia-zh-cn/' target=\"_blank\">微软亚洲研究院</a>\n  实习，指导导师是\n  <a href='https://recmind.cn/' target=\"_blank\">李东胜</a>\n  博士，并与\n  <a href='https://victorywys.github.io/' target=\"_blank\">王延森</a>\n  博士和\n  <a href='https://frosthan.github.io/' target=\"_blank\">韩东起</a>\n  博士一起在 \n  <a href='https://www.microsoft.com/en-us/research/group/shanghai-ai-ml-group/?locale=zh-cn' target=\"_blank\">Shanghai AI/ML Group</a> 进行研究。",address:"地址: 〒 153-8505 東京都目黒区駒場 4-6-1 東京大学 生産技術研究所",email:"个人邮箱: nielin@iis.u-tokyo.ac.jp",phone:"个人电话: +81 080-5637-8886 (日本)",web:"个人网站: lin-nie.github.io",newTitle:"消息",navigation:{name:"林涅",address:["主页","消息","研究兴趣","论文发表","项目经验","个人经历","专业经验","荣誉奖项","发表专利","软件著作","参与基金"]},new:{new1:"[ 2019.08 ] 在Prof. Lvy Wang的指导下，我在<strong>加拿大多伦多大学</strong>完成了一个关于数学与机器学习的研究项目。为我以后关于<strong>计算机视觉</strong>的研究奠定数学基础。",new2:"[ 2019.12 ] 我以年级第一的优异成绩获得了2019年的<strong>一等奖学金</strong>。谢谢!",new3:"[ 2020.03 ] 在大二寒假期间，我在<strong>哈尔滨工业大学（深圳）</strong>廖教授的指导下参与研究实习，通过深度学习完成关于<strong>视频理解与分析</strong>项目。",new4:"[ 2020.08 ] 我在<strong>新加坡国立大学</strong>完成了<strong>人工智能与深度学习</strong>领域的项目学习。并获得由新加坡国立大学颁发的<strong>荣誉奖</strong>。",new5:"[ 2020.09 ] 恭喜，我通过层层选拔加入<strong>工业人工智能技术研究院(IIAIT)</strong>，并由来自<strong>清华大学</strong>的陈高教授指导展开关于数字图像处理方面的研究。",new6:"[ 2020.10 ] 我获得中国人工智能电子设计大赛三等奖 !!",new7:"[ 2020.12 ] 我以年级第一的优异成绩获得了2020年的<Strong>一等奖学金</Strong>以及<Strong> 高伟光企业奖学金(杰出工程代表) </Strong>。谢谢!",new8:'[ 2021.01 ] 我们团队以<Strong>13/2207</Strong>的排名进入<a href="https://www.ccf.org.cn/en/">中国计算机学会(CCF) </a> <Strong>人工智能视觉算法大赛</Strong>决赛。一次很赞的团队合作体验!!',new9:"[ 2021.05 ] 我在美国数学建模竞赛USA MCM/ICM 中获得<Strong>国际二等奖</Strong>。",new10:"[ 2021.06 ] 开始在湖南大学的計算機視覺实验室担任 <Strong>研究助理</Strong>。 由<a href='https://cai-mj.github.io/'>蔡 敏捷</a>教授担任指导老师。<a href=\"https://www.linnie.com.cn/documents/Research_Assistant_Minjie_Cai_Hunan_University.pdf\">[研究證明]</a>",new11:"[ 2021.10 ] 我从我们的实验室得到了属于我自己的<Strong>头戴式相机</Strong>，未来将尝试收集第一人称数据集。谢谢!",new12:"[ 2021.12 ] 我以年级第一的优异成绩获得了2021年的<Strong>一等奖奖学金</Strong>、<Strong>岭南学术奖学金(优秀学术代表)</Strong>，谢谢!",new13:"[ 2022.05 ] 恭喜! 我获得了<a href='http://www.moe.gov.cn/jyb_xxgk/s5743/s5744/A05/202112/t20211216_587869.html'>中华人民共和国国家奖学金</a>, 由<a href='http://en.moe.gov.cn/'>中华人民共和国教育部</a>颁布, 这是中国最高级别的奖学金项目! (<Strong>全国排名前0.01%的学生</Strong>).",new14:"[ 2022.06 ] 我的毕业论文<strong>《基于自我中心视频中无监督域适应的第一人称动作识别》</strong>顺利通过了本科毕业设计论文答辩。",new15:"[ 2022.06 ] 恭喜! 我以<strong>专业第一名</strong>(<strong>Rank 1st / 78</strong>)取得<a>工学学士</a>，并且顺利毕业于<a>东莞理工 计算机软件工程专业</a>， 获得<strong>优秀本科毕业生</strong>。",new16:'[ 2022.06 ] 恭喜! 我的论文在<a href="https://eyewear-computing.org/EPIC_CVPR22/">CVPR-EPIC 2022</a>中关于<Strong>无监督域适应第一人称动作识别</Strong>顺利被接收, 在<a href="https://cai-mj.github.io/">蔡 敏捷</a>教授的指导下。 预印本和代码均可用. <a href="https://arxiv.org/abs/2207.03095">[預印本]</a> <a href="https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA">[Github代码]</a>',new17:'[ 2022.07 ] 我受邀参加今年<a href="https://cvpr2022.thecvf.com/">CVPR 2022</a> 并参与 <a href="https://eyewear-computing.org/EPIC_CVPR22/">EPIC 2022</a> 演讲。<br><a href="./img/cvpr_2022_meeting_photo1.png">[會議照片1]&<a><a href="./img/cvpr_2022_meeting_photo2.png">[會議照片2]&<a><a href="./img/cvpr_2022_meeting_photo3.png">[會議照片3]&<a><a href="./img/cvpr_2022_meeting_photo4.png">[會議照片4]&<a><a href="./img/cvpr_2022_meeting_photo5.png">[會議照片5]&<a><a href="./img/cvpr_2022_meeting_photo6.png">[會議照片6]<a>',new18:'[ 2022.07 ] 我们关于<Strong>知识迁移学习</Strong>的论文已经被今年的<Strong>ECCV 2022</Strong>正式接受!! 代码已经开源。<a href="https://arxiv.org/pdf/2207.05409.pdf">[論文]</a><a href="https://arxiv.org/abs/2207.05409">[預印本]</a><a href="https://github.com/dzy3/KCD">[Github代碼]</a>',new19:'[ 2022.08 ] 在<a href="https://cai-mj.github.io/">蔡 敏捷</a>教授的指导下，我在今年的<Strong>BMVC 2022</Strong>上提交了一篇<Strong>基于自我中心视频中手部区域与第一人称动作识别相关的</Strong>论文。代码将会开源！！',new20:'[ 2022.09 ] 我非常希望我能尽快申请研究生和硕士，开始我的新项目:<Strong>EgoV: 从虚拟到现实</Strong>。<a href="http://www.linnie.com.cn/projects/egov/">[项目页面]</a><a href="http://www.linnie.com.cn/documents/NieLin_HNU_UTokyo_EgoV_Research_Proposal.pdf">[研究计划书]</a>'},biographyTitle:"个人经历",biography:{bio1:{introduce:"(2021.6-至今)  助理研究员. 指导教授为",mentor:"蔡 敏捷",brief1:"信息科学与工程学院, 计算机视觉实验室",brief2:"湖南大学"}},exchangeTitle:"专业经验",exchangeSubtitle:"本人非常热衷于科研交流，以下为经常交流学习的大学：",exchange:[{imgName:"清华大学",href:"https://www.tsinghua.edu.cn/en/",intro:'<p style="font-size: 20px">\n              清華大学\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学排名ーーNo.17\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学排名ーーNo.28\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学排名ーーNo.20\n              </p>\n              <br><p style="font-size: 15px">\n              ARWU 2021: 世界大学排名ーーNo.29\n              </p>\n                '},{imgName:"NUS",href:"https://www.nus.edu.sg/",intro:'<p style="font-size: 20px">\n              シンガポール国立大学（NUS）\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学排名ーーNo.11\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学排名ーーNo.32\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学排名ーーNo.25\n              </p>\n              <br><p style="font-size: 15px">\n\n              </p>\n      '},{imgName:"TORONTO",href:"https://www.utoronto.ca/",intro:'<p style="font-size: 20px">\n              トロント大学（UofT）\n              </p> \n              <br><p style="font-size: 14.9px">\n              QS 2021: 世界大学排名ーーNo.26\n              </p>\n              <br><p style="font-size: 14.9px">\n              U.S. New : 世界大学排名ーーNo.17\n              </p>\n              <br><p style="font-size: 14.9px">\n              THE 2021: 世界大学排名ーーNo.18\n              </p>\n              <br><p style="font-size: 14.9px">\n              ARWU 2021: 世界大学排名ーーNo.23\n              </p>\n      '},{imgName:"香港科技大学",href:"https://hkust.edu.hk/",intro:'\n              <p style="font-size: 20px">\n              ホンコン科技大学（HKUST）\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学排名ーーNo.34\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学排名ーーNo.109\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学排名ーーNo.56\n              </p>\n              <br><p style="font-size: 15px">\n           \n              </p>\n      '}],profExprience:[{name:"1. 湖南大学 (HNU)",workplace:"长沙, 中国",topic:"研究课题: 基于手部区域的第一人称动作识别",title:"助理研究员",supervisor:" 指导教授: 蔡 敏捷 教授 [湖南大学]"},{name:"2. 工业人工智能技术研究所 (IIAIT)",workplace:"东莞, 中国",topic:"研究课题: 数字图像处理",title:"助理研究员",supervisor:" 指导教授: 陈高教授 [清华大学]"},{name:"3. 哈尔滨工业大学 (HIT)",workplace:"深圳, 中国",topic:"研究课题: 视频分析与理解",title:"研究实习生",supervisor:" 指导教授: 廖清教授 [哈尔滨工业大学(深圳)]"},{name:"4. 多伦多大学 (UofT)",workplace:"多伦多, 加拿大",topic:"研究课题: 数学与机器学习",title:"项目学生",supervisor:" 指导教授: Lvy Wang教授 [多伦多大学]"}],researchTitle:"研究兴趣",overallField:"整体领域",researchOverInterest:["计算机视觉 (CV)","第一人称视觉 (FPV)","人机交互 (HCI),"],specialField:"特别兴趣",researchSpecialInterest:["1. 自我中心的视频理解和分析","2. 动作识别","3. 手部区域分析","4. 域适应与泛化","5. 知识迁移学习",".........................."],awardsTitle:"荣誉奖项",scholarship:"所获奖学金",scholar1:"1. 中华人民共和国国家奖学金",scholar1explain:"[中华人民共和国教育部]",scholar1supp:"(中国排名前0.1%的学生)",scholar2:"2. 岭南学术奖学金  [杰出的学术代表]",scholar3:"3. 2021年学年度一等奖奖学金   [年级GPA第一名，2021年]",scholar4:"4. 高伟光企业奖学金   [杰出的工程代表]",scholar5:"5. 2020年学年度一等奖奖学金   [年级GPA第一名，2020年]",scholar6:"6. 2019年学年度一等奖奖学金   [年级GPA第一名，2019年]",awards:[{subtitle:"奖励",content:["广东省优秀本科毕业生","优秀本科生的论文","美国数学建模竞赛国际二等奖","中国计算机学会AI视觉算法大赛 (排名13/2207)","中国人工智能电子设计大赛三等奖","新加坡国立大学荣誉奖","华为优秀开发者奖"]}],conferenceTitle:"论文发表",conferencePublication:[{name:"EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022 Technical Report",author:"<Strong>Nie Lin</Strong>, <a href='https://cai-mj.github.io/' target=\"_blank\">Minjie Cai</a><sup>✉</sup>",match:"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR-EPIC), 2022",match2:"",paper:"[论文]",projectPage:"[项目页面]",code:"[Github代码]",video:"[视频]"},{name:"Knowledge Condensation Distillation",author:"Chenxin Li, <a href='https://lmbxmu.github.io/'>Mingbao Lin</a>, Zhiyuan Ding, <Strong>Nie Lin</Strong>, Yihong Zhuang, <a href='https://huangyue05.github.io/'>Yue Huang</a><sup>✉</sup>,...",match:"European Conference on Computer Vision (ECCV), 2022",match2:"",paper:"[论文]]",projectPage:"",code:"[Github代码]",video:""}],journalTitle:"期刊论文",journalPublication:[{name:"暂无"}],patentTitle:"发表专利",patent:[{name:"基于模拟信号处理的人机交互感知设备",author:'<a href="#">林涅</a>, 刘婵梓博士, 黎浩锋, 邹世豪, 李俊裕',number:"CN 202022246705.5"}],copyrghtTitle:"软件著作",softwareCopyrght:[{name:"日文邮政支付票据 OCR识别安卓客户端App（日文邮政票 OCR App）",Number:"软著登字第 A0003976号"},{name:"基于人工智能的视频版权保护系统",Number:"软著登字第 4840268号"}],projectsTitle:"项目经验",projectsHightLight:"高亮",projectsNote:" 表示最近开展的项目。",recentlyProjects:[{name:"EgoV: 一个全新的跨越真实和虚拟的以自我中心视频的数据集",author:"<strong>！！作为一个全新的长期项目，将会在我硕士阶段展开！！</strong>",match:"",match2:"",paper:"[研究计划书]",projectPage:"[项目页面]",code:"[Github代码]",video:"[视频]"},{name:"基于自中心视频手部区域的无监督域适应第一人称动作识别",author:"<strong>林 涅</strong>, 蔡 敏捷",match:"湖南大学",match2:"",paper:"[论文]",projectPage:"[项目页面]",code:"[Github代码]",video:"[视频]",photo:"[会议照片]"},{name:"基于迁移学习的知识浓缩蒸馏",author:"李 宸鑫, 林 明宝, <strong>林 涅</strong>, 庄毅鸿, 黄悦",match:"厦门大学 & 湖南大学",paper:"[论文]",projectPage:"[项目页面]",code:"[Github代码]",video:"[视频]"},{name:"第一人称视角下的数据集采集 (通过头戴式摄像头)",author:"<strong>林 涅</strong>",match:"湖南大学",paper:"",projectPage:"",code:"",video:""}],pastProjects:[{name:"多模态视频分析与理解",author:"<strong>林 涅</strong>, 郭 凡, 王 杰, 丁 烨, 廖 清",match:"哈尔滨工业大学 (HIT) ",match2:"",paper:"",projectPage:"",code:"",video:"[video]"},{name:"基于OpenMV机器视觉的手球动作识别控制系统",author:"<strong>林 涅</strong>, 王 斌, 周 清峰",match:"中国人工智能电子设计大赛",match2:"",paper:"",projectPage:"",code:"",video:""}],scientificFundTitle:"参与基金",scientificFund:[{name:'<a href="#">国家自然科学基金</a>',match:"国家自然科学基金号：No. 61971138"},{name:"广东省基础与应用基础研究资助项目",match:"项目基金号：No. 2019A1515111149"},{name:"广东省高等教育创新与高校发展工程",match:"工程基金号：No. 2020ZDZX3047"}],footer:{period:"© 2018 - 2025   林涅",lastUpdated:"上次更新: 2025年02月10日"}};var be=we;o["a"].use(le["a"]);var _e=new le["a"].Store({state:{words:ue,dictionary:{en:ue,zh:be,jp:me}},mutations:{SET_LANGUAGE(t,e){t.words=t.dictionary[e]}},actions:{setLanguage({commit:t},e){t("SET_LANGUAGE",e)}},getters:{words(t){return t.words}},modules:{}}),ve=(n("63bf"),n("ecee")),ye=n("c074"),Ce=n("b702"),je=n("f2d1"),Se=n("ad3d");ve["c"].add(ye["a"],Ce["a"],je["a"]),o["a"].component("font-awesome-icon",Se["a"]),o["a"].component("font-awesome-layers",Se["b"]),o["a"].component("font-awesome-layers-text",Se["c"]),o["a"].config.productionTip=!1,new o["a"]({store:_e,render:t=>t(ge)}).$mount("#app")},cfa2:function(t,e,n){t.exports=n.p+"img/xx.5a35d7e2.png"},d268:function(t,e,n){"use strict";n("1c8f")},d4d5:function(t,e,n){var o={"./0.gif":"0db5","./1.gif":"2d4f","./2.gif":"4382","./3.gif":"d6b6"};function r(t){var e=i(t);return n(e)}function i(t){if(!n.o(o,t)){var e=new Error("Cannot find module '"+t+"'");throw e.code="MODULE_NOT_FOUND",e}return o[t]}r.keys=function(){return Object.keys(o)},r.resolve=i,t.exports=r,r.id="d4d5"},d6b6:function(t,e,n){t.exports=n.p+"img/3.9c599d8e.gif"},e199:function(t,e,n){},e466:function(t,e,n){var o={"./0.png":"0554","./1.png":"064c"};function r(t){var e=i(t);return n(e)}function i(t){if(!n.o(o,t)){var e=new Error("Cannot find module '"+t+"'");throw e.code="MODULE_NOT_FOUND",e}return o[t]}r.keys=function(){return Object.keys(o)},r.resolve=i,t.exports=r,r.id="e466"},f5f6:function(t,e,n){t.exports=n.p+"img/LINNIE_10062023_japan.5cd844b9.jpg"},fbd7:function(t,e,n){"use strict";n("728c")}});
//# sourceMappingURL=app.2a64a084.js.map