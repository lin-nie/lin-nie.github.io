(function(e){function t(t){for(var r,a,s=t[0],c=t[1],p=t[2],h=0,l=[];h<s.length;h++)a=s[h],Object.prototype.hasOwnProperty.call(o,a)&&o[a]&&l.push(o[a][0]),o[a]=0;for(r in c)Object.prototype.hasOwnProperty.call(c,r)&&(e[r]=c[r]);g&&g(t);while(l.length)l.shift()();return i.push.apply(i,p||[]),n()}function n(){for(var e,t=0;t<i.length;t++){for(var n=i[t],r=!0,s=1;s<n.length;s++){var c=n[s];0!==o[c]&&(r=!1)}r&&(i.splice(t--,1),e=a(a.s=n[0]))}return e}var r={},o={app:0},i=[];function a(t){if(r[t])return r[t].exports;var n=r[t]={i:t,l:!1,exports:{}};return e[t].call(n.exports,n,n.exports,a),n.l=!0,n.exports}a.m=e,a.c=r,a.d=function(e,t,n){a.o(e,t)||Object.defineProperty(e,t,{enumerable:!0,get:n})},a.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},a.t=function(e,t){if(1&t&&(e=a(e)),8&t)return e;if(4&t&&"object"===typeof e&&e&&e.__esModule)return e;var n=Object.create(null);if(a.r(n),Object.defineProperty(n,"default",{enumerable:!0,value:e}),2&t&&"string"!=typeof e)for(var r in e)a.d(n,r,function(t){return e[t]}.bind(null,r));return n},a.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return a.d(t,"a",t),t},a.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)},a.p="";var s=window["webpackJsonp"]=window["webpackJsonp"]||[],c=s.push.bind(s);s.push=t,s=s.slice();for(var p=0;p<s.length;p++)t(s[p]);var g=c;i.push([0,"chunk-vendors"]),n()})({0:function(e,t,n){e.exports=n("cd49")},"0554":function(e,t,n){e.exports=n.p+"img/0.3cffc5ad.png"},"0558":function(e,t,n){},"064c":function(e,t,n){e.exports=n.p+"img/1.17b8ddf2.png"},"071d":function(e,t,n){"use strict";n("14e4")},"0aa0":function(e,t,n){"use strict";n("bc6e")},"0cad":function(e,t,n){"use strict";n("0558")},"0ced":function(e,t,n){e.exports=n.p+"img/1.ff7e5f6e.png"},"0db5":function(e,t,n){e.exports=n.p+"img/0.a86f88b4.gif"},"14e4":function(e,t,n){},"19f8":function(e,t,n){},"1c8f":function(e,t,n){},"1dd2":function(e,t,n){"use strict";n("766e")},2155:function(e,t,n){e.exports=n.p+"img/NUS.e8930f16.jpg"},"22e7":function(e,t,n){var r={"./NUS.jpg":"2155","./TORONTO.jpg":"ccb7","./清华大学.jpg":"23f8","./香港科技大学.jpg":"297f"};function o(e){var t=i(e);return n(t)}function i(e){if(!n.o(r,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return r[e]}o.keys=function(){return Object.keys(r)},o.resolve=i,e.exports=o,o.id="22e7"},"23f8":function(e,t,n){e.exports=n.p+"img/清华大学.c111f20f.jpg"},"297f":function(e,t,n){e.exports=n.p+"img/香港科技大学.e64963c4.jpg"},"2d4f":function(e,t,n){e.exports=n.p+"img/1.d7893ebd.gif"},"37cb":function(e,t,n){},"3a96":function(e,t,n){var r={"./0.png":"5fd6","./1.png":"0ced","./2.png":"714a","./x.png":"b976","./xx.png":"cfa2","./xxx.png":"4da8"};function o(e){var t=i(e);return n(t)}function i(e){if(!n.o(r,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return r[e]}o.keys=function(){return Object.keys(r)},o.resolve=i,e.exports=o,o.id="3a96"},"3c15":function(e,t,n){"use strict";n("19f8")},4382:function(e,t,n){e.exports=n.p+"img/2.19e7276e.gif"},"4da8":function(e,t,n){e.exports=n.p+"img/xxx.e4047474.png"},"4f9b":function(e,t,n){},5574:function(e,t,n){},"55ba":function(e,t,n){},"5d3f":function(e,t,n){"use strict";n("bdb4")},"5fd6":function(e,t,n){e.exports=n.p+"img/0.d6279389.png"},"62c3":function(e,t,n){},"63bf":function(e,t,n){},"6e86":function(e,t,n){"use strict";n("37cb")},"714a":function(e,t,n){e.exports=n.p+"img/2.4f5481f0.png"},"728c":function(e,t,n){},"766e":function(e,t,n){},"8aa4":function(e,t,n){},"8c41":function(e,t,n){"use strict";n("55ba")},9591:function(e,t,n){"use strict";n("5574")},"9af6":function(e,t,n){"use strict";n("8aa4")},"9dee":function(e,t,n){"use strict";n("a9be")},a69c:function(e,t,n){"use strict";n("4f9b")},a9be:function(e,t,n){},afd3:function(e,t,n){"use strict";n("f0d4")},b976:function(e,t,n){e.exports=n.p+"img/x.bbfff928.png"},bc6e:function(e,t,n){},bdb4:function(e,t,n){},ccb7:function(e,t,n){e.exports=n.p+"img/TORONTO.084008c3.jpg"},cd49:function(e,t,n){"use strict";n.r(t);var r=n("2b0e"),o=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{attrs:{id:"app"}},[t("Header"),t("div",{staticClass:"container href",attrs:{id:"Home"}},[t("Profile"),t("info-list"),t("NavigationBar"),t("New"),t("ResearchInterest"),t("Publication"),t("Projects"),t("Biography"),t("ProfessionalExperience"),t("Honors"),t("Patent"),t("SoftwareCopyrght"),t("ScientificFund"),t("Footer")],1)],1)},i=[],a=n("9ab4"),s=n("1b40"),c=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"header-wrapper"},[t("div",{staticClass:"content-wrapper"},[t("div",{staticClass:"left"},[t("div",{staticClass:"name"},[t("span",[e._v(e._s(e.words.name))])]),t("div",{staticClass:"blog"},[e._v(e._s(e.words.blog))])]),t("div",{staticClass:"right"},e._l(e.LanguageItems,(function(n,r){return t("div",{key:r,staticClass:"language-item",on:{click:()=>e.changeLanguage(n)}},[e._v(" "+e._s(n.__identity)+" ")])})),0)])])},p=[],g=(n("e9f5"),n("ab43"),n("4bb5"));let h=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e])}changeLanguage(e){this.$store.dispatch("setLanguage",e.__langKey)}};Object(a["a"])([Object(s["b"])()],h.prototype,"msg",void 0),Object(a["a"])([Object(g["a"])("words")],h.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],h.prototype,"dictionary",void 0),h=Object(a["a"])([s["a"]],h);var l=h,d=l,u=(n("9af6"),n("2877")),f=Object(u["a"])(d,c,p,!1,null,"7eb63195",null),m=f.exports,b=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"info-list-wrapper"},[e._l(e.longInfoList,(function(n,r){return t("div",{key:r,staticClass:"long-info-list list-item"},[t("font-awesome-icon",{staticClass:"icon",attrs:{icon:n.icon}}),e._v(" "+e._s(n.msg)+" ")],1)})),t("div",{staticClass:"short-list-wrapper"},e._l(e.shortInfoList,(function(n,r){return t("div",{key:r,staticClass:"short-info-list list-item"},[t("font-awesome-icon",{staticClass:"icon",attrs:{icon:n.icon}}),e._v(" "+e._s(n.msg)+" ")],1)})),0),t("div",{staticClass:"icons"},e._l(e.icons,(function(n,r){return t("div",{key:r,staticClass:"icon"},[t("a",{staticStyle:{display:"block"},attrs:{href:n.href}},[t("font-awesome-icon",{staticClass:"icon",style:{color:n.hovTheme,backgroundColor:n.bgC},attrs:{icon:n.icon},on:{mouseenter:()=>e.setColor(n),mouseleave:()=>e.resetColor(n)}})],1)])})),0)],2)},w=[];let _=class extends s["c"]{constructor(){super(...arguments),this.icons=[{hovTheme:"#000",icon:["fab","github"],href:"https://github.com/lin-nie",theme:"rgb(255, 0, 0)"},{hovTheme:"#000",icon:["fab","google"],href:"https://scholar.google.com/citations?hl=en&user=3sybTOUAAAAJ",theme:"rgb(67, 135, 246)"},{hovTheme:"#000",icon:["fab","linkedin"],href:"https://www.linkedin.com/in/nie-lin/",theme:"rgb(0, 127, 178)"},{hovTheme:"#000",icon:["fab","twitter-square"],href:"https://twitter.com/NieLin6",theme:"rgb(29, 155, 240)"}]}created(){}get longInfoList(){return[{icon:["fas","home"],msg:this.words.address}]}get shortInfoList(){return[{icon:["fas","envelope"],msg:this.words.email},{icon:["fas","phone-alt"],msg:this.words.phone},{icon:["fas","tv"],msg:this.words.web}]}setColor(e){e.hovTheme=e.theme}resetColor(e){e.hovTheme="#000",e.bgC="#fff"}};Object(a["a"])([Object(g["a"])("words")],_.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],_.prototype,"dictionary",void 0),_=Object(a["a"])([s["a"]],_);var v=_,y=v,C=(n("0aa0"),Object(u["a"])(y,b,w,!1,null,"a7b7cca0",null)),P=C.exports,j=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"profile-wrapper"},[t("div",{staticClass:"profile-info-wrapper"},[e._m(0),t("div",{staticClass:"profile"},[t("h1",{staticClass:"name"},[e._v(" "+e._s(e.words.name)+" ")]),t("p",{staticClass:"advance-line"},[e._v(" "+e._s(e.words.degree)+" ")]),t("p",{staticClass:"advance-line"},[e._v(" "+e._s(e.words.major)+" ")]),t("p",{staticClass:"small-line"},[e._v(" "+e._s(e.words.academy)+" ")]),t("p",{staticClass:"small-line"},[e._v(" "+e._s(e.words.department)+" "),t("span",{staticStyle:{"font-weight":"600"}},[e._v(e._s(e.words.researchStudent))])]),t("hr",{staticStyle:{"margin-top":"10px"}}),t("div",{staticClass:"introduction"},[t("ul",{staticClass:"content"},[t("p",{domProps:{innerHTML:e._s(e.words.personalIntroduction)}}),t("p",{staticStyle:{"margin-top":"5px"}},[t("font",{attrs:{color:"red"},domProps:{innerHTML:e._s(e.words.notification1)}}),t("br"),t("a",{attrs:{href:"http://www.linnie.com.cn/documents/curriculum_vitae.pdf"}},[e._v(e._s(e.words.curriculum_vitae))]),e._v("       "),t("a",{attrs:{href:"http://www.linnie.com.cn/documents/academic_transcripts.pdf"}},[e._v(e._s(e.words.academic_transcripts))]),e._v("       "),t("a",{attrs:{href:"http://www.linnie.com.cn/documents/NieLin_HNU_UTokyo_EgoV_Research_Proposal.pdf"}},[e._v(e._s(e.words.research_proposal))]),e._v(" &  "),t("a",{attrs:{href:"http://www.linnie.com.cn/projects/egov/"}},[e._v(e._s(e.words.project_page))]),e._v("    "),t("a",{attrs:{href:"http://www.linnie.com.cn/img/cvpr_2022_meeting_photo1.png"}},[e._v(e._s(e.words.meeting_photo))]),e._v("   "),t("br"),t("a",{attrs:{href:"http://www.linnie.com.cn/documents/recommendation_letter.pdf"}},[e._v(e._s(e.words.recommendation_letter))]),e._v("       "),t("a",{attrs:{href:"http://www.linnie.com.cn/documents/research_certificate.pdf"}},[e._v(e._s(e.words.research_certificate))]),e._v("     "),t("a",{attrs:{href:"http://www.linnie.com.cn/documents/PRC_scholarship.pdf"}},[e._v(e._s(e.words.PRC_scholarship))]),e._v(" "),t("br"),t("br"),t("font",{attrs:{color:"red"},domProps:{innerHTML:e._s(e.words.notification2)}}),t("br"),t("a",{attrs:{href:"http://www.linnie.com.cn/documents/certificate_of_diploma.pdf"}},[e._v(e._s(e.words.diploma_certificate))]),e._v("       "),t("a",{attrs:{href:"http://www.linnie.com.cn/documents/certificate_of_bachelor_degree.pdf"}},[e._v(e._s(e.words.bachelor_certificate))]),e._v("       "),t("a",{attrs:{href:"http://www.linnie.com.cn/documents/certificate_of_grade_first_ranking.pdf"}},[e._v(e._s(e.words.ranking_certificate))]),e._v("       ")],1)])])])]),t("div",{staticClass:"address-wrapper"}),e._m(1)])},S=[function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"profile-image"},[t("img",{attrs:{src:n("e429")}})])},function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"info-wrapper"},[t("div",{staticClass:"infos"}),t("div",{staticClass:"icons"})])}];let x=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],x.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],x.prototype,"dictionary",void 0),x=Object(a["a"])([s["a"]],x);var T=x,I=T,N=(n("dde4"),Object(u["a"])(I,j,S,!1,null,"84ede5c2",null)),O=N.exports,A=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"navigation-wrapper"},[t("ul",[t("p",{staticClass:"name"},[e._v(e._s(e.words.navigation.name))]),e._l(e.words.navigation.address,(function(n,r){return t("li",[t("a",{staticClass:"menu-item",attrs:{href:"#"+e.href[r]}},[e._v(e._s(n))])])}))],2)])},H=[];let U=class extends s["c"]{constructor(){super(...arguments),this.href=["Home","New","Research Interest","Publication","Projects","Biography","Professional Experience","Honors","Patent","Software Copyrght","Fund Participation"]}get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],U.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],U.prototype,"dictionary",void 0),U=Object(a["a"])([s["a"]],U);var L=U,E=L,k=(n("0cad"),Object(u["a"])(E,A,H,!1,null,"5a767f6d",null)),R=k.exports,M=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"new-wrapper wrapper-style href",attrs:{id:"New"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.newTitle)+" ")])])]),t("ul",{staticClass:"show-list"},[t("li",{domProps:{innerHTML:e._s(e.words.new.new20)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new19)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new18)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new17)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new16)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new15)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new14)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new13)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new12)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new11)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new10)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new9)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new8)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new7)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new6)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new5)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new4)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new3)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new2)}}),t("li",{domProps:{innerHTML:e._s(e.words.new.new1)}})])])},V=[];let z=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],z.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],z.prototype,"dictionary",void 0),z=Object(a["a"])([s["a"]],z);var F=z,D=F,G=(n("a69c"),Object(u["a"])(D,M,V,!1,null,null,null)),K=G.exports,B=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"research-wrapper wrapper-style href",attrs:{id:"Research Interest"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.researchTitle)+" ")])])]),t("ul",{staticClass:"research-content"},[t("Strong",[e._v(e._s(e.words.overallField))]),t("br"),e._l(e.words.researchOverInterest,(function(n){return t("li",[e._v(" "+e._s(n)+" ")])})),t("br"),t("Strong",[e._v(e._s(e.words.specialField))]),t("br"),e._l(e.words.researchSpecialInterest,(function(n){return t("li",[e._v(" "+e._s(n)+" ")])}))],2)])},Q=[];let W=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],W.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],W.prototype,"dictionary",void 0),W=Object(a["a"])([s["a"]],W);var Z=W,Y=Z,J=(n("8c41"),Object(u["a"])(Y,B,Q,!1,null,"f0a999b6",null)),X=J.exports,$=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"projects-wrapper wrapper-style href",attrs:{id:"Publication"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.conferenceTitle)+" ")])])]),t("div",e._l(e.words.conferencePublication,(function(r,o){return t("div",{staticClass:"project-component"},[t("div",{staticClass:"projects-img"},[t("a",{attrs:{href:"javascript:;"}},[t("img",{attrs:{src:n("e466")(`./${o}.png`),alt:""}})])]),t("div",{staticClass:"content"},[t("strong",[e._v(e._s(r.name))]),t("img",{attrs:{src:"http://www.linnie.com.cn/img/new.gif"}}),t("p",{domProps:{innerHTML:e._s(r.author)}}),t("p",[e._v(e._s(r.match))]),t("p",[e._v(e._s(r.match2))]),0==o?t("div",[t("a",{attrs:{href:"https://arxiv.org/abs/2207.03095"}},[e._v(e._s(r.paper))]),t("a",{attrs:{href:"http://www.linnie.com.cn/projects/uda_action/"}},[e._v(e._s(r.projectPage))]),t("a",{attrs:{href:"https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA"}},[e._v(e._s(r.code))]),t("a",{attrs:{href:"https://www.youtube.com/watch?v=BnVhNeUBau4"}},[e._v(e._s(r.video))])]):e._e(),1==o?t("div",[t("a",{attrs:{href:"https://arxiv.org/abs/2207.05409"}},[e._v(e._s(r.paper))]),t("a",{attrs:{href:"https://github.com/dzy3/KCD"}},[e._v(e._s(r.code))])]):e._e(),e._l(r.label,(function(n){return t("span",{staticClass:"label"},[e._v(e._s(n))])}))],2)])})),0)])},q=[];let ee=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],ee.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],ee.prototype,"dictionary",void 0),ee=Object(a["a"])([s["a"]],ee);var te=ee,ne=te,re=(n("d268"),Object(u["a"])(ne,$,q,!1,null,"2c8f5f8c",null)),oe=re.exports,ie=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"projects-wrapper wrapper-style href",attrs:{id:"Projects"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.projectsTitle)+" ")])])]),t("h4",[t("span",{staticStyle:{"background-color":"#ffffd0"}},[e._v(e._s(e.words.projectsHightLight))]),e._v(e._s(e.words.projectsNote)+" ")]),t("div",{staticStyle:{background:"#ffffd0"}},e._l(e.words.recentlyProjects,(function(r,o){return t("div",{staticClass:"project-component"},[t("div",{staticClass:"projects-img"},[t("a",{attrs:{href:"javascript:;"}},[t("img",{attrs:{src:n("d4d5")(`./${o}.gif`),alt:""}})])]),t("div",{staticClass:"content"},[t("strong",[e._v(e._s(r.name))]),t("p",{domProps:{innerHTML:e._s(r.author)}}),t("p",[e._v(e._s(r.match))]),t("p",[e._v(e._s(r.match2))]),0==o?t("div",[t("a",{attrs:{href:"http://www.linnie.com.cn/documents/NieLin_HNU_UTokyo_EgoV_Research_Proposal.pdf"}},[e._v(e._s(r.paper))]),t("a",{attrs:{href:"http://www.linnie.com.cn/projects/egov/"}},[e._v(e._s(r.projectPage))]),t("a",{attrs:{href:"http://www.linnie.com.cn/projects/egov/"}},[e._v(e._s(r.code))]),t("a",{attrs:{href:"http://www.linnie.com.cn/projects/egov/videos/egov_4k.mp4"}},[e._v(e._s(r.video))])]):e._e(),1==o?t("div",[t("a",{attrs:{href:"https://arxiv.org/pdf/2207.03095.pdf"}},[e._v(e._s(r.paper))]),t("a",{attrs:{href:"http://www.linnie.com.cn/projects/uda_action/"}},[e._v(e._s(r.projectPage))]),t("a",{attrs:{href:"https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA"}},[e._v(e._s(r.code))]),t("a",{attrs:{href:"https://www.youtube.com/watch?v=BnVhNeUBau4"}},[e._v(e._s(r.video))]),t("a",{attrs:{href:"./img/cvpr_2022_meeting_photo1.png"}},[e._v(e._s(r.photo))])]):e._e(),2==o?t("div",[t("a",{attrs:{href:"https://arxiv.org/abs/2207.05409"}},[e._v(e._s(r.paper))]),t("a",{attrs:{href:"https://github.com/dzy3/KCD"}},[e._v(e._s(r.code))])]):e._e(),3==o?t("div",[e._v(" "+e._s(r.video)+" ")]):e._e(),e._l(r.label,(function(n){return t("span",{staticClass:"label"},[e._v(e._s(n))])}))],2)])})),0),e._l(e.words.pastProjects,(function(r,o){return t("div",{staticClass:"project-component"},[t("div",{staticClass:"projects-img"},[t("a",{attrs:{href:"javascript:;"}},[t("img",{attrs:{src:n("3a96")(`./${o}.png`),alt:""}})])]),t("div",{staticClass:"content"},[t("strong",[e._v(e._s(r.name))]),t("p",{domProps:{innerHTML:e._s(r.author)}}),t("p",[e._v(e._s(r.match))]),t("p",[e._v(e._s(r.match2))]),0==o?t("div",[t("a",{attrs:{href:"https://ieeexplore.ieee.org/document/9689024"}},[e._v(e._s(r.paper))]),e._v(" "+e._s(r.projectPage)+" "+e._s(r.code)+" "+e._s(r.video)+" "),t("a",{attrs:{href:"./img/ieee_icsip_meeting_photo.png"}},[e._v(e._s(r.photo))])]):e._e(),e._l(r.label,(function(n){return t("span",{staticClass:"label"},[e._v(e._s(n))])}))],2)])}))],2)},ae=[];let se=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],se.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],se.prototype,"dictionary",void 0),se=Object(a["a"])([s["a"]],se);var ce=se,pe=ce,ge=(n("6e86"),Object(u["a"])(pe,ie,ae,!1,null,"69d1cbca",null)),he=ge.exports,le=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"biography-wrapper wrapper-style"},[t("div",[t("section",{staticClass:"title"},[t("h2",{staticClass:"href",attrs:{id:"Biography"}},[e._v(" "+e._s(e.words.biographyTitle)+" ")])])]),t("div",[t("p",{staticClass:"biography-content"},[e._v(" "+e._s(e.words.biography.bio1.introduce)+" "),t("a",{attrs:{href:"https://cai-mj.github.io/"}},[e._v(e._s(e.words.biography.bio1.mentor))]),t("br"),e._v(" "+e._s(e.words.biography.bio1.brief1)),t("br"),t("strong",[e._v(e._s(e.words.biography.bio1.brief2))])]),t("p",{staticClass:"biography-content"},[e._v(" "+e._s(e.words.biography.bio2.introduce)),t("br"),e._v(" "+e._s(e.words.biography.bio2.brief1)),t("br"),t("strong",[e._v(e._s(e.words.biography.bio2.brief2))])])])])},de=[];let ue=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],ue.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],ue.prototype,"dictionary",void 0),ue=Object(a["a"])([s["a"]],ue);var fe=ue,me=fe,be=(n("afd3"),Object(u["a"])(me,le,de,!1,null,"1dc8f9c8",null)),we=be.exports,_e=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"experience-wrapper wrapper-style href",attrs:{id:"Professional Experience"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.exchangeTitle)+" ")])])]),t("div",{staticClass:"subtitle"},[t("strong",[e._v(e._s(e.words.exchangeSubtitle))])]),t("div",{staticClass:"img-box"},e._l(e.words.exchange,(function(r){return t("div",{staticClass:"exchange-img"},[t("img",{attrs:{src:n("22e7")(`./${r.imgName}.jpg`),alt:""}}),t("a",{attrs:{href:r.href}},[t("div",{staticClass:"mask-desc"},[t("div",{staticClass:"mask-content",domProps:{innerHTML:e._s(r.intro)}})])])])})),0),t("br"),t("div",[t("ul",e._l(e.words.profExprience,(function(n){return t("li",[t("strong",[e._v(e._s(n.name))]),t("br"),e._v(" "+e._s(n.workplace)),t("span",{domProps:{innerHTML:e._s("              ")}}),e._v(e._s(n.topic)),t("br"),e._v(" "+e._s(n.title)+","+e._s(n.supervisor)+" ")])})),0)])])},ve=[];let ye=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],ye.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],ye.prototype,"dictionary",void 0),ye=Object(a["a"])([s["a"]],ye);var Ce=ye,Pe=Ce,je=(n("5d3f"),Object(u["a"])(Pe,_e,ve,!1,null,"19165cb6",null)),Se=je.exports,xe=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"awards-wrapper wrapper-style href",attrs:{id:"Honors"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.awardsTitle)+" ")])])]),e._l(e.words.awards,(function(n){return t("ul",{staticClass:"awards-content"},[t("p",[e._v(e._s(e.words.scholarship))]),t("a",{attrs:{href:"http://www.moe.gov.cn/jyb_xxgk/s5743/s5744/A05/202112/t20211216_587869.html"}},[e._v(e._s(e.words.scholar1))]),e._v("   "+e._s(e.words.scholar1explain)),t("br"),t("i",[e._v(e._s(e.words.scholar1supp))]),t("br"),e._v(" "+e._s(e.words.scholar2)),t("br"),e._v(" "+e._s(e.words.scholar3)),t("br"),e._v(" "+e._s(e.words.scholar4)),t("br"),e._v(" "+e._s(e.words.scholar5)),t("br"),e._v(" "+e._s(e.words.scholar6)),t("br"),t("p",[e._v(e._s(n.subtitle))]),e._l(n.content,(function(n){return t("li",[e._v(e._s(n))])}))],2)}))],2)},Te=[];let Ie=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],Ie.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],Ie.prototype,"dictionary",void 0),Ie=Object(a["a"])([s["a"]],Ie);var Ne=Ie,Oe=Ne,Ae=(n("9dee"),Object(u["a"])(Oe,xe,Te,!1,null,"60aafcf6",null)),He=Ae.exports,Ue=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"publication"},[t("div",{staticClass:"patent-wrapper wrapper-style href",attrs:{id:"Patent"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.patentTitle)+" ")])])]),t("ul",{staticClass:"content"},e._l(e.words.patent,(function(n){return t("li",[t("strong",[e._v(e._s(n.name))]),t("p",{domProps:{innerHTML:e._s(n.author)}}),t("p",{domProps:{innerHTML:e._s(n.number)}})])})),0)])])},Le=[];let Ee=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],Ee.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],Ee.prototype,"dictionary",void 0),Ee=Object(a["a"])([s["a"]],Ee);var ke=Ee,Re=ke,Me=(n("1dd2"),Object(u["a"])(Re,Ue,Le,!1,null,"4b1834b5",null)),Ve=Me.exports,ze=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"copyrght-wrapper wrapper-style href",attrs:{id:"Software Copyrght"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.copyrghtTitle)+" ")])])]),t("ul",{staticClass:"copyrght-content"},e._l(e.words.softwareCopyrght,(function(n){return t("li",[t("strong",[e._v(e._s(n.name))]),t("p",{domProps:{innerHTML:e._s(n.Number)}})])})),0)])},Fe=[];let De=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],De.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],De.prototype,"dictionary",void 0),De=Object(a["a"])([s["a"]],De);var Ge=De,Ke=Ge,Be=(n("3c15"),Object(u["a"])(Ke,ze,Fe,!1,null,"47db2168",null)),Qe=Be.exports,We=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"tutorial-wrapper wrapper-style href",attrs:{id:"Fund Participation"}},[t("div",[t("section",{staticClass:"title"},[t("h2",[e._v(" "+e._s(e.words.scientificFundTitle)+" ")])])]),t("ul",{staticClass:"content"},e._l(e.words.scientificFund,(function(n){return t("li",[t("strong",{domProps:{innerHTML:e._s(n.name)}}),t("p",{domProps:{innerHTML:e._s(n.match)}})])})),0)])},Ze=[];let Ye=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],Ye.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],Ye.prototype,"dictionary",void 0),Ye=Object(a["a"])([s["a"]],Ye);var Je=Ye,Xe=Je,$e=(n("9591"),Object(u["a"])(Xe,We,Ze,!1,null,"429e83f7",null)),qe=$e.exports,et=function(){var e=this,t=e._self._c;e._self._setupProxy;return t("div",{staticClass:"footer-wrapper wrapper-style"},[t("p",[e._v(e._s(e.words.footer.period))]),t("p",{staticClass:"update"},[t("strong",[e._v(e._s(e.words.footer.lastUpdated))])])])},tt=[];let nt=class extends s["c"]{get LanguageItems(){return Object.keys(this.dictionary).map(e=>this.dictionary[e].__identity)}};Object(a["a"])([Object(g["a"])("words")],nt.prototype,"words",void 0),Object(a["a"])([Object(g["b"])("dictionary")],nt.prototype,"dictionary",void 0),nt=Object(a["a"])([s["a"]],nt);var rt=nt,ot=rt,it=(n("071d"),Object(u["a"])(ot,et,tt,!1,null,"c0cae402",null)),at=it.exports;let st=class extends s["c"]{};st=Object(a["a"])([Object(s["a"])({components:{Header:m,Profile:O,InfoList:P,NavigationBar:R,New:K,ResearchInterest:X,Publication:oe,Projects:he,Biography:we,ProfessionalExperience:Se,Honors:He,Patent:Ve,SoftwareCopyrght:Qe,ScientificFund:qe,Footer:at}})],st);var ct=st,pt=ct,gt=(n("fbd7"),Object(u["a"])(pt,o,i,!1,null,null,null)),ht=gt.exports,lt=n("2f62");const dt={__identity:"English",__langKey:"en",name:"Nie Lin",degree:"Undergraduate Student (Graduated at 2022.06)",major:"Computer Science Software Engineering (GPA: 3.6 Ranked: 1st/78 students)",academy:"Research Assistant",department:"College of Computer Science and Electronic Engineering, Hunan University ",researchStudent:"(Now)",personalIntroduction:'Hi! I am <strong>Nie Lin</strong>. I got my bachelor\'s degree in engineering in June 2022, and now I am working as a <strong>research assistant</strong> in\n  <strong><a href=\'http://www-en.hnu.edu.cn/index.htm\' target="_blank">\n  Hunan University</a></strong>, supervised by \n  <strong><a href=\'https://cai-mj.github.io/\' target="_blank">\n  Prof. Minjie Cai</a></strong>. \n  <br>My research interests include \n  <strong>Computer Vision (CV)</strong>. \n  <strong>Especially in First-person Vision (FPV)</strong>, \n  <strong>Human-computer Interactions (HCI)</strong>, \n  I focus on\n  <strong>Human sensing and understanding <br>of human activities</strong>.\n  I have a strong interest in FPV research, welcome to \n  <a herf="mailto:nielin@hnu.edu.cn">\n  contact me</a>.',notification1:"<img src=\"http://www.linnie.com.cn/img/new.gif\">：<br>\n  (a) <b><i>My application status</i></b>：I am looking for the lab in the direction of <b>the first-person vision in computer vision</b> and applying to the Master's program and PhD program at the university where the lab is located. Email and online meeting are always welcome!<br>\n  (b) <b><i>My research objects</i></b>：My research objects is to build more powerful <b>human-centered artificial intelligence that can 'think'</b> through the exploration and discovery of <b>the first-person perspective in computer vision</b>, , which can <b>adapt to complex and changeable environments!</b><br>\n  (c) <b><i>My life goals</i></b>：My life goal is to become a computer vision researcher, serve as an independent faculty advisor at a university in the future, <b>and do impressive and influential work around the world.</b><br>\n  (d) <b><i>My academic planning</i></b>：After completing the master's course, <b>I will continue to complete the Phd course</b>, so as to continuously improve my scientific research ability.<br><br>\n  The following is about my application materials (academic)：\n  ",curriculum_vitae:"1. [Curriculum Vitae]",academic_transcripts:"2. [Academic Transcripts]",research_proposal:"3. [Research Proposal]",project_page:"[Project Page]",meeting_photo:"4. [CVPR Meeting Photo]",recommendation_letter:"5. [Recommendation Letter (Minjie Cai)]",research_certificate:"6. [Research Certificate (Hunan University)]",PRC_scholarship:"7. [National Scholarship of People’s Republic of China]",notification2:"The following is about my application materials (basic) :\n  ",diploma_certificate:"8. [Certification of Diploma]",bachelor_certificate:"9. [Certification of Bachelor’s Degree]",ranking_certificate:"10. [Certification of Grade 1st Ranking]",address1:"Address1: Room 9A411 Institute of AI-Net Electronic Information & Artificial Intelligence, DGUT, Dongguan, China",address:"Address: Room 433 College of Computer Science and Electronic Engineering, Hunan University, Changsha, China (Now)",email:"Email: nielin@hnu.edu.cn",phone:"Phone: +86 131-3835-0137",web:"Web: linnie.com.cn",navigation:{name:"Nie Lin",address:["Home","News","Research Interests","Publications","Projects","Biography","Professional Experience","Honors","Patents","Software Copyright","Fund Participation"]},newTitle:"News",new:{new1:"[ 2019.08 ] Under the leadership of Prof. Lvy Wang, I completed a research project on mathematics and machine learning in <Strong>University of Toronto, Canada</Strong>. Lay a mathematical foundation for my future research in <Strong>Computer Vision</Strong>.",new2:"[ 2019.12 ] I won 2019 year's <Strong>The First Prize Scholarship</Strong> for being the first in my grade. Thanks!",new3:"[ 2020.03 ] During the winter vacation, I worked as a research intern under the guidance of Prof. Qing Liao from <Strong>Harbin Institute of Technology (HIT)</Strong> to complete the project of <Strong>video understanding and analysis</Strong> through deep learning.",new4:"[ 2020.08 ] I completed my exchange programme study in the field of <Strong>Artificial Intelligence and Deep Learning</Strong> in the <Strong>National University of Singapore</Strong>. And won the <Strong>Honorary Award of the National University of Singapore</Strong>.",new5:"[ 2020.09 ] Congratulations, I successfully joined the <Strong>Institute of Industrial Artificial Intelligence Technology (IIAIT)</Strong> in Songshan Lake, Dongguan through multiple selection, and was supervised by <Strong>Prof. Gao Chen from Tsinghua University</Strong>.",new6:"[ 2020.10 ] I got The Third prize of <Strong>China Artificial Intelligence Electronic Design Competition</Strong>. Congratulations !!",new7:"[ 2020.12 ] I won 2020 year's <Strong>The First Prize Scholarship</Strong> and <Strong>The Kao Wei-kwong Enterprise Scholarship (Outstanding Engineering Representative) </Strong> for being the first in my grade. Thanks!",new8:"[ 2021.01 ] Our team successfully entered the <a href='https://www.ccf.org.cn/en/'>China Computer Federation (CCF) </a> <Strong>Artificial Intelligence Vision Algorithm Competition</Strong> and final with the rank of <Strong>13/2207</Strong>. A great team work experience !!",new9:"[ 2021.05 ] I won the <Strong>international second prize</Strong> in the American Mathematical Contest In Modeling (USA MCM).",new10:"[ 2021.06 ] Started research working as a <Strong>Research Assistant</Strong> at Computer Vision Lab, Hunan University. <br>Supervised by Prof. <a href='https://cai-mj.github.io/'>Minjie Cai</a>.<a href=\"https://www.linnie.com.cn/documents/Research_Assistant_Minjie_Cai_Hunan_University.pdf\">[Research Certificate]</a>",new11:"[ 2021.10 ] I got my own <Strong>head-mounted camera</Strong> from our laboratory and will be trying to collect the first-person dataset in the future. Thanks!",new12:"[ 2021.12 ] I won 2021 year's <Strong>The First Prize Scholarship</Strong> and <Strong>The Lingnan Academic Scholarship (Outstanding Academic Representative) </Strong> for being the first in my grade. Thanks!",new13:"[ 2022.05 ] Congratulations! I won the <a href='http://www.moe.gov.cn/jyb_xxgk/s5743/s5744/A05/202112/t20211216_587869.html'>National Scholarship of the People's Republic of China</a>, issued by the <a href='http://en.moe.gov.cn/'>Ministry of Education of China</a>, which is the highest level scholarship program in China! (<Strong>TOP 0.01% Students in China</Strong>).",new14:'[ 2022.06 ] My graduation thesis <Strong>"First-person Action Recognition Based on Unsupervised Domain Adaptation in Egocentric Video"</Strong> successfully pass the thesis defense of undergraduate graduation design.',new15:"[ 2022.06 ] Congratulations! I successfully graduated from <Strong>DGUT Computer Software Engineering</Strong> with <strong>the first place</strong> in my major (<strong>Rank 1st / 78</strong> ) with a <Strong>Bachelor of Engineering degree</Strong>. And won the <Strong>Outstanding Undergraduate Graduate</Strong>",new16:'[ 2022.06 ] Congratulations! My paper on <a href="https://eyewear-computing.org/EPIC_CVPR22/">CVPR-EPIC 2022</a> about <Strong>UDA Frist-person Action Recognition</Strong> has been successfully accepted, under the supervision of Prof. <a href="https://cai-mj.github.io/">Minjie Cai</a>. The arXiv and code is available. <a href="https://arxiv.org/abs/2207.03095">[ArXiv]</a> <a href="https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA">[Github Code]</a>',new17:'[ 2022.07 ] I was invited to attend this year\'s <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a> and participate in the <a href="https://eyewear-computing.org/EPIC_CVPR22/">EPIC 2022</a> presentation. <br><a href="./img/cvpr_2022_meeting_photo1.png">[Meeting Photo1]&<a><a href="./img/cvpr_2022_meeting_photo2.png">[Meeting Photo2]&<a><a href="./img/cvpr_2022_meeting_photo3.png">[Meeting Photo3]&<a><a href="./img/cvpr_2022_meeting_photo4.png">[Meeting Photo4]&<a><a href="./img/cvpr_2022_meeting_photo5.png">[Meeting Photo5]&<a><a href="./img/cvpr_2022_meeting_photo6.png">[Meeting Photo6]<a>',new18:'[ 2022.07 ] Our paper on <Strong>Knowledge Transfer Learning</Strong> has been accepted for <Strong>ECCV 2022</Strong>!! Paper and code is available. <br><a href="https://arxiv.org/pdf/2207.05409.pdf">[Paper]</a><a href="https://arxiv.org/abs/2207.05409">[Arxiv]</a><a href="https://github.com/dzy3/KCD">[Github Code]</a>',new19:'[ 2022.08 ] Under the guidance of Prof. <a href="https://cai-mj.github.io/">Minjie Cai</a>, I submitted a paper at <Strong>BMVC 2022</Strong> this year based on <Strong>hand regions in egocentric videos related to first-personaction recognition</Strong>. Code will be open source !!',new20:'[ 2022.09 ] I really hope that I can apply for a research student and master as soon as possible to start my new project: <Strong>EgoV: From Virtual to Real </Strong>. <a href="http://www.linnie.com.cn/projects/egov/">[Project Page]</a><a href="http://www.linnie.com.cn/documents/NieLin_HNU_UTokyo_EgoV_Research_Proposal.pdf">[Research Proposal]</a>'},biographyTitle:"Biography",biography:{bio1:{introduce:"(2021.6 - Now) Research Assistant. Supervised by Prof.",mentor:"Minjie Cai",brief1:"College of Computer Science and Electronic Engineering, Computer Vision Lab",brief2:"Hunan University"},bio2:{introduce:"(2018.9 - 2022.6) BSc in Computer Science & Software Engineering (Graduated at 2022.06)",brief1:"Institute of Industrial Artificial Intelligence Technology (IIAIT)",brief2:"Dongguan University of Technology"}},exchangeTitle:"Professional Experience",exchangeSubtitle:"I am very keen on scientific research exchange，the following are the Universities where I often communicate and study :",exchange:[{imgName:"清华大学",href:"https://www.tsinghua.edu.cn/en/",intro:'<p style="font-size: 20px">\n              Tsinghua University\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: No.17 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : No.28 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: No.20 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              ARWU 2021: No.29 in the world University Rankings\n              </p>\n               '},{imgName:"NUS",href:"https://www.nus.edu.sg/",intro:'<p style="font-size: 20px">\n              National University of Singapore\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: No.11 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : No.32 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: No.25 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n\n              </p>\n      '},{imgName:"TORONTO",href:"https://www.utoronto.ca/",intro:'<p style="font-size: 20px">\n              University of Toronto\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: No.26 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : No.17 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: No.18 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              ARWU 2021: No.23 in the world University Rankings\n              </p>\n      '},{imgName:"香港科技大学",href:"https://hkust.edu.hk/",intro:'\n              <p style="font-size: 20px">\n              Hong Kong University of Science and Technology\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: No.34 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : No.109 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: No.56 in the world University Rankings\n              </p>\n              <br><p style="font-size: 15px">\n           \n              </p>\n      '}],profExprience:[{name:"1. Hunan University (HNU)",workplace:"Changsha, China",topic:"Topic: First-person Action Recognition base on Hand Region",title:"Research Assistant",supervisor:" Supervisor: Prof. Minjie Cai [Hunan University]"},{name:"2. Institute of Industrial Artificial Intelligence Technology (IIAIT)",workplace:"Dongguan, China",topic:"Topic: Digital Image Processing",title:"Research Assistant",supervisor:" Supervisor: Prof. Gao Chen [Tsinghua University]"},{name:"3. Harbin Institute of Technology (HIT)",workplace:"Shenzhen, China",topic:"Topic: Video Analysis and Understanding",title:"Research Intern",supervisor:" Supervisor: Prof. Qing Liao [Harbin Institute of Technology]"},{name:"4. University of Toronto (UofT)",workplace:"Toronto, Canada",topic:"Topic: Mathematics and Machine Learning",title:"Project Student",supervisor:" Supervisor: Prof. Lvy Wang [University of Toronto]"}],researchTitle:"Research Interests",overallField:"Overall Field",researchOverInterest:["Computer Vision (CV)","First-person Vision (FPV)","Human-computer Interactions (HCI)"],specialField:"Special Interests",researchSpecialInterest:["1. Egocentric Video Understanding and Analysis","2. Action Recognition","3. Hand Region Analysis","4. Domain Adaptation & Generalization","5. Knowledge Transfer Learning",".........................."],awardsTitle:"Honors",scholarship:"Scholarship",scholar1:"1. National Scholarship of the People's Republic of China",scholar1explain:"[Ministry of Education of China]",scholar1supp:"(TOP 0.1% Students in China)",scholar2:"2. The Lingnan Academic Scholarship  [Outstanding Academic Representative]",scholar3:"3. The First Prize Scholarship   [The First Place of GPA in the Grade, 2021]",scholar4:"4. The Kao Wei-kwong Enterprise Scholarship   [Outstanding Engineering Representative]",scholar5:"5. The First Prize Scholarship   [The First Place of GPA in the Grade, 2020]",scholar6:"6. The First Prize Scholarship   [The First Place of GPA in the Grade, 2019]",awards:[{subtitle:"Awards",content:["Outstanding Undergraduate of Guangdong Province","Outstanding Undergraduate's Thesis","International Second Prize in the American Mathematical Contest In Modeling","China Computer Federation AI Vision Algorithm Competition (Rank 13/2207)","The Third prize of China Artificial Intelligence Electronic Design Competition","Honorary Award of the National University of Singapore","Excellent Huawei Developer Award"]}],conferenceTitle:"Publications",conferencePublication:[{name:"EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022 Technical Report",author:"<Strong>Nie Lin</Strong>, <a href='https://cai-mj.github.io/' target=\"_blank\">Minjie Cai</a><sup>✉</sup>",match:"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR-EPIC), 2022",match2:"",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"Knowledge Condensation Distillation",author:"Chenxin Li, <a href='https://lmbxmu.github.io/'>Mingbao Lin</a>, Zhiyuan Ding, <Strong>Nie Lin</Strong>, Yihong Zhuang, <a href='https://huangyue05.github.io/'>Yue Huang</a><sup>✉</sup>,...",match:"European Conference on Computer Vision (ECCV), 2022",match2:"",paper:"[Paper]",projectPage:"",code:"[Github Code]",video:""}],journalTitle:"Journal Publication",journalPublication:[{}],patentTitle:"Patents",patent:[{name:"Human-computer Interaction (HCI) Sensing Devices based on Analog Signal Processing",author:'<a href="">Nie Lin</a>, Chanzhi Liu, Haofeng Li, Shihao Zou, Junyu Li, Ruofan Hu',number:"CN 202022246705.5"}],copyrghtTitle:"Software Copyright",softwareCopyrght:[{name:"OCR Recognition System for Japanese Postal Payment Notes",Number:"No.A0003976 in SoftwareCopyright"},{name:"Video copyright protection system based on artificial intelligence",Number:"No.4840268 in SoftwareCopyright"}],projectsTitle:"Projects",projectsHightLight:"Highlighted",projectsNote:" projects are recently projects.",recentlyProjects:[{name:"EgoV: A New Datasets of Egocentric Videos Across Real and Virtual",author:"<strong>!! As a new long-term research project will be carried out at my master's level !!</strong>",match:"",match2:"",paper:"[Research Proposal]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"UDA First-person Action Recognition based on Hand Regions in Egocentric Videos",author:"<strong>Nie Lin</strong>, Minjie Cai",match:"Hunan University",match2:"",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]",photo:"[Meeting Photo]"},{name:"Knowledge Condensation Distillation base on Transfer Learning",author:"Chenxin Li, Mingbao Lin, <strong>Nie Lin</strong>, Yihong Zhuang, Yue Huang",match:"Xiamen & Hunan University, Tencent Youtu Lab",paper:"[Paper]",projectPage:"[Project Page]",code:"[Github Code]",video:"[Video]"},{name:"Dataset Acquisition from First-person Perspective (Through Head-mounted Camera)",author:"<strong>Nie Lin</strong>",match:"Hunan University",paper:"",projectPage:"",code:"",video:""}],pastProjects:[{name:"Dilated Residual Shrinkage Network for Digital Image Despeckling",author:"<strong>Nie Lin</strong>, Gao Chen, Qingfeng Zhou, Chanzi Liu",match:"Institute of Industrial Artificial Intelligence Technology (IIAIT)",match2:"",paper:"[Paper]",projectPage:"",code:"",video:"",photo:"[Meeting Photo]"},{name:"Multi-Modal Video Analysis and Understanding",author:"<strong>Nie Lin</strong>, Fan Guo, Jie Wang, Ye Ding, Qing Liao",match:"Harbin Institute of Technology (HIT) ",match2:"",paper:"",projectPage:"",code:"",video:"[video]"},{name:"Hand-ball Action Recognition Control System based on OpenMV Machine Vision",author:"<strong>Nie Lin</strong>, Bing Wang, Qingfeng Zhou",match:"China Artificial Intelligence Electronic Design Competition",match2:"",paper:"",projectPage:"",code:"",video:""}],scientificFundTitle:"Fund Participation",scientificFund:[{name:'<a href="https://www.nsfc.gov.cn/english/site_1/index.html">The National Natural Science Foundation of China</a>',match:"No. 61971138 in the Scientific Fund"},{name:"Basic and Applied Basic Research Project of Guangdong Province under Grant",match:"No. 2019A1515111149 in the Scientific Fund"},{name:"Guangdong Higher Education Innovation and College Development Project",match:"No. 2020ZDZX3047 in the Scientific Fund"}],footer:{period:"© 2018 - 2022   Nie Lin",lastUpdated:"Last updated: August 31,2022"}};var ut=dt;const ft={__identity:"日本語",__langKey:"jp",name:"林 涅（リン ネエ）",degree:"学部生 (2022年6月卒業しました)",major:"コンピューター ソフトウェア工学 (GPA: 3.6 ランキング: 専攻 1st/78 位)",academy:"アシスタント研究員",department:"情報科学工学部, 湖南大学",researchStudent:"(現在)",personalIntroduction:'こんにちは~ 中国からの<strong>林 涅</strong>です。専攻はソフトウェア工学で、東莞理工大学を卒業しました。 \n  現在、私は\n  <a href="https://cai-mj.github.io/" target="_blank">\n  蔡 敏捷</a>\n  教授のもとで、\n  <a href="http://www-en.hnu.edu.cn/index.htm" target="_blank">\n  湖南大学</a>\n  で研究と勉強をしています。\n  <br>私の研究趣味は\n  <strong>コンピュータビジョン(CV)</strong>、\n  特に<strong>一人称視点映像解析(FPV)</strong>、\n  <strong>コンピュータグラフィック(CG)</strong>、\n  <strong>ヒューマンコンピュータインタラクション(HCI)</strong>です。\n  私は<strong>一人称視点映像解析研究</strong>に深い興味を持っており、交流することを歓迎します。\n  ',notification1:'<img src="http://www.linnie.com.cn/img/new.gif">：<br>\n  (a) <b><i>私の現状:</b></i> 私は<b>コンピュータビジョンにおける一人称ビジョン</b>の研究室を探しており、その研究室がある大学の修士課程および博士課程<br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp\n  に応募しています。<br>\n  (b) <b><i>私の研究:</b></i> 私の将来の研究目標は、<b>コンピュータビジョンにおける一人称視点の探索と発見</b>を通じて、より強力な<b>人間中心の「思考」型<br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp\n  人工知能</b>を構筑することです!<br>\n  (c) <b><i>私の目標:</b></i> 私の目標はコンピュータの視覚の科学研究者になることで、将来大学で独立した指導教員を担当して、<b>世界で印象深く影響力<br>&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp\n  のある仕事をします</b>。<br>\n  (d) <b><i>私の計画:</b></i> 私は修士の段階の課程を完成した后に<b>引き続き博士の課程</b>を申請して、これによって絶えず私の科学研究の能力を高めます。<br><br>\n  以下は私の出願書類についてです(学術):：\n  ',curriculum_vitae:"1. [ポロフィール]",academic_transcripts:"2. [成績表]",research_proposal:"3. [研究計画書]",project_page:"[プロジェクト ページ]",meeting_photo:"4. [CVPR会議参加]",recommendation_letter:"5. [推薦状 (蔡敏捷)]",research_certificate:"6. [研究証明書 (湖南大学))]",PRC_scholarship:"7. [中華人民共和国国家級奨学金]",notification2:"以下は私の出願書類についてです(基本):\n  ",diploma_certificate:"8. [卒業証明書]",bachelor_certificate:"9. [学士学位証明書]",ranking_certificate:"10. [専攻第一位証明書]",address1:"アドレス1: 中国広東省東莞市 DGUT-9A411 Ai-Net電子情報&人工知能研究所",address:"アドレス: 中国湖南省長沙市 湖南大学 情報科学及び工程学院研究生弁公室433 (現在)",email:"メールアドレス: nielin@hnu.edu.cn",phone:"電話番号: +86 131-3835-0137",web:"ホームページ: linnie.com.cn",newTitle:"ニュース",navigation:{name:"リン ネエ",address:["ホームページ","ニュース","研究趣味","発表論文","プロジェクト","バイオグラフィー","専門経験","奨学金・受賞","発明特许","ソフトウエア著作権","研究ファンド"]},new:{new1:"[ 2019.08 ] Prof. Lvy Wangのご指導により、<strong>カナダのトロント大学（UofT）</strong>で私は数学と機械学習に関する研究プロジェクトを取り組みました。今後の<strong>コンピュータビジョン</strong>に関する研究に数学の基礎を築きくれました。",new2:"[ 2019.12 ] 私は<strong>学年トップ1の成績</strong>で2019年度の<strong>一等奨学金</strong>を受賞しました。ありがとうございます!",new3:"[ 2020.03 ] 二年生の冬休み、<strong>ハルビン工業大学（HIT）</strong>の<strong>Prof. Liao</strong>のご指導により、私は研究実習に参加し、ディープ・ラーニングを用いて<strong>ビデオの理解と分析</strong>に関するプロジェクトを完成しました。",new4:"[ 2020.08 ] 私は<strong>シンガポール国立大学（NUS）</strong>で<strong>人工知能とディープラーニングのプロジェクトスタディ</strong>を修了しました。シンガポール国立大学から<strong>栄誉賞</strong>を受賞しました。",new5:"[ 2020.09 ] 【祝】数回の選抜を経て、私は<strong>工業人工知能技術研究院(IIAIT)</strong>に入選しました。これから<strong>清華大学</strong>陳高先生のご指導により、デジタル画像処理に関する研究を展開します。",new6:"[ 2020.10 ] <Strong>中国人工知能電子デザインコンテスト</Strong>で三等賞を受賞しました !!",new7:"[ 2020.12 ] 私は<strong>学年トップ1の成績</strong>で2020年の<strong>一等奨学金</Strong>及び<Strong>高偉光企業奨学金(傑出工程代表)</strong>を受賞しました。ありがとうございます。",new8:'[ 2021.01 ] うちのチームは13/2207の順位で<a href= "https://www.ccf.org.cn/en/">中国コンピュータ学会（CCF）</a><Strong>人工知能視覚アルゴリズムコンテストの決勝戦</Strong>に入選しました。素晴らしいチームワークでした！！',new9:"[ 2021.05 ] 【祝】アメリカ数学モデリングコンテスト(USA MCM/ICM)で<Strong>国際二等賞</Strong>を受賞しました！",new10:'[ 2021.06 ] 湖南大学のコンピュータビジョン研究室で<strong>アシスタント研究員</strong>として務め始めました。<br>指導先生は<a href="https://cai-mj.github.io/">蔡 敏捷教授</a>です, よろしくお願いします~<a href="https://www.linnie.com.cn/documents/Research_Assistant_Minjie_Cai_Hunan_University.pdf">[研究證明]</a>',new11:"[ 2021.10 ] 研究室から自分の<Strong>ヘッドセット・カメラ</Strong>をゲットしました。これを使って<Strong>一人称データセット</Strong>の収集を試みます。ありがとうございます。",new12:"[ 2021.12 ] 私は<Strong>学年トップ1の成績</Strong>で2021年の<Strong>一等奨学金</Strong>及び<Strong>嶺南学術奨学金(優秀学術代表)</Strong>を獲得しました。ありがとうございます。",new13:"[ 2022.05 ] 【祝】<a href='http://en.moe.gov.cn/'>中華人民共和国教育部</a>から<a href='http://www.moe.gov.cn/jyb_xxgk/s5743/s5744/A05/202112/t20211216_587869.html'>国家レベル奨学金</a>を受賞しました。これは中国最高レベルの奨学金プログラムです。（<Strong>全国上位0.01%の学生</Strong>）.",new14:"[ 2022.06 ] 私の卒業論文<strong>「エゴセントリックビデオにおけるUDA適応に基づく一人称行動認識」</strong>は、無事に答弁に合格しました。",new15:"[ 2022.06 ] 【祝】私は<strong>専攻の第一位(Rank 1st / 78</strong>)として<strong>工学学士</strong>を取得し、順調に<strong>東莞理工コンピュータソフトウェア工程</strong>専攻から卒業しました。そして<strong>優秀卒業生を受賞</strong>しました。",new16:'[ 2022.06 ] 【祝】<a href="https://cai-mj.github.io/">蔡敏捷 先生</a>のご指導のもとで、私の<Strong>無監督ドメイン適応について一人称動作認識</Strong>に関する論文は<a href="https://eyewear-computing.org/EPIC_CVPR22/">CVPR-EPIC 2022</a>に採択されました。論文とコードは利用可能です。<a href="https://arxiv.org/abs/2207.03095">[ArXiv 预印本]</a> <a href="https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA">[Github代码]</a>',new17:'[ 2022.07 ] 私は今年の<a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>に招待されて、<a href="https://eyewear-computing.org/EPIC_CVPR22/">EPIC 2022</a>の講演に参加しました。<br><a href="./img/cvpr_2022_meeting_photo1.png">[会議の写真1]&<a><a href="./img/cvpr_2022_meeting_photo2.png">[会議の写真2]&<a><a href="./img/cvpr_2022_meeting_photo3.png">[会議の写真3]&<a><a href="./img/cvpr_2022_meeting_photo4.png">[会議の写真4]&<a><a href="./img/cvpr_2022_meeting_photo5.png">[会議の写真5]&<a><a href="./img/cvpr_2022_meeting_photo6.png">[会議の写真6]<a>.',new18:'[ 2022.07 ] 私たちのノウレッジ・トランスファー・ラーニングに関する論文はECCV 2022に採択されました。論文とコードは利用可能です。<a href="https://arxiv.org/pdf/2207.05409.pdf">[論文]</a><a href="https://arxiv.org/abs/2207.05409">[Arxiv プリプリント]</a><a href="https://github.com/dzy3/KCD">[Github コード]</a>',new19:'[ 2022.08 ] <a href="https://cai-mj.github.io/">蔡敏捷 先生</a>のご指導のもとで、<strong>BMVC 2022</strong>に<strong>エゴセントリックビデオにおける手の一人称行動認識に関する論文</strong>を提出しました。コードはまもなくオープンソースになります~',new20:'[ 2022.09 ] できるだけ早く日本の大学院に応募して、自分の新たしいプロジェクト「EgoV：バーチャルからリアルへ」を始めたいと思います。<a href="http://www.linnie.com.cn/projects/egov/">[プロジェクト ページ]</a><a href="http://www.linnie.com.cn/documents/NieLin_HNU_UTokyo_EgoV_Research_Proposal.pdf">[研究計画書]</a>'},biographyTitle:"バイオグラフィー",biography:{bio1:{introduce:"(2021.6-現在)  アシスタント研究員. 指導教員は准教授",mentor:"蔡 敏捷",brief1:"情報科学工学部, Computer Vision Lab",brief2:"湖南大學"},bio2:{introduce:"(2018.9 - 2022.6)  コンピューター ソフトウェア工学 (卒業は2022年6月)",brief1:"産業用人工知能技術研究所 (IIAIT)",brief2:"東莞理工大學"}},exchangeTitle:"専門経験",exchangeSubtitle:"私は非常に科学研究の交流に熱心です、以下はよく交流して勉強している大学です：",exchange:[{imgName:"清华大学",href:"https://www.tsinghua.edu.cn/en/",intro:'<p style="font-size: 20px">\n              清華大学\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学のランキングーーNo.17\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学のランキングーーNo.28\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学のランキングーーNo.20\n              </p>\n              <br><p style="font-size: 15px">\n              ARWU 2021: 世界大学のランキングーーNo.29\n              </p>\n                '},{imgName:"NUS",href:"https://www.nus.edu.sg/",intro:'<p style="font-size: 20px">\n              シンガポール国立大学（NUS）\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学のランキングーーNo.11\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学のランキングーーNo.32\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学のランキングーーNo.25\n              </p>\n              <br><p style="font-size: 15px">\n\n              </p>\n      '},{imgName:"TORONTO",href:"https://www.utoronto.ca/",intro:'<p style="font-size: 20px">\n              トロント大学（UofT）\n              </p> \n              <br><p style="font-size: 14.9px">\n              QS 2021: 世界大学のランキングーーNo.26\n              </p>\n              <br><p style="font-size: 14.9px">\n              U.S. New : 世界大学のランキングーーNo.17\n              </p>\n              <br><p style="font-size: 14.9px">\n              THE 2021: 世界大学のランキングーーNo.18\n              </p>\n              <br><p style="font-size: 14.9px">\n              ARWU 2021: 世界大学のランキングーーNo.23\n              </p>\n      '},{imgName:"香港科技大学",href:"https://hkust.edu.hk/",intro:'\n              <p style="font-size: 20px">\n              ホンコン科技大学（HKUST）\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学のランキングーーNo.34\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学のランキングーーNo.109\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学のランキングーーNo.56\n              </p>\n              <br><p style="font-size: 15px">\n           \n              </p>\n      '}],profExprience:[{name:"1. 湖南大学 (HNU)",workplace:"長沙, 中国",topic:"研究テーマ: 手部領域に基づく一人称働作認識",title:"アシスタント研究員",supervisor:" 指導教授: 蔡 敏捷 教授 [湖南大学]"},{name:"2. 工业人工智能技术研究所 (IIAIT)",workplace:"东莞, 中国",topic:"研究课题: 数字图像处理",title:"アシスタント研究員",supervisor:" 指导教授: 陈高教授 [清华大学]"},{name:"3. 哈尔滨工业大学 (HIT)",workplace:"深圳, 中国",topic:"研究课题: 视频分析与理解",title:"研究实习生",supervisor:" 指导教授: 廖清教授 [哈尔滨工业大学(深圳)]"},{name:"4. 多伦多大学 (UofT)",workplace:"多伦多, 加拿大",topic:"研究课题: 数学与机器学习",title:"项目学生",supervisor:" 指导教授: Lvy Wang教授 [多伦多大学]"}],researchTitle:"研究趣味",overallField:"Overall Field",researchOverInterest:["コンピュータビジョン (CV)","一人称視覚 (FPV)","ヒューマンコンピュータインタラクション (HCI),"],specialField:"Special Interests",researchSpecialInterest:["1. 自己中心的なビデオ理解と分析","2. 行動認識","3. 手部区域解析","4. ドメイン適応と一般化","5. 知識移動学習",".........................."],awardsTitle:"奨学金・受賞",scholarship:"奨学金",scholar1:"1. 中華人民共和国国家奨学金",scholar1explain:"[中華人民共和国教育部]",scholar1supp:"(中国の上位0.1%の学生)",scholar2:"2. 嶺南学術奨学金  [傑出した学術の代表]",scholar3:"3. 2021年度 一等奨学金   [学年GPA 1位、2021年]",scholar4:"4. 高偉光企業奨学金   [傑出した工事の代表]",scholar5:"5. 2020年度 一等奨学金   [学年GPA 1位、2020年]",scholar6:"6. 2019度 一等奨学金   [学年GPA 1位、2019年]",awards:[{subtitle:"受賞",content:["広東省の優秀な学部卒業生","優秀な学部生の論文","米国数学モデリングコンテスト国際2位","中国コンピュータ学会AI視覚アルゴリズム大会 (順位13/2207)","中国人工知能電子デザインコンテスト3等賞","シンガポール国立大学名誉賞","ファーウェイ優秀開発者賞"]}],conferenceTitle:"発表論文",conferencePublication:[{name:"EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022 Technical Report",author:"<Strong>Nie Lin</Strong>, <a href='https://cai-mj.github.io/' target=\"_blank\">Minjie Cai</a><sup>✉</sup>",match:"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR-EPIC), 2022",match2:"",paper:"[論文]",projectPage:"[プロジェクト ページ]",code:"[コード]",video:"[ビデオ]"},{name:"Knowledge Condensation Distillation",author:"Chenxin Li, <a href='https://lmbxmu.github.io/'>Mingbao Lin</a>, Zhiyuan Ding, <Strong>Nie Lin</Strong>, Yihong Zhuang, <a href='https://huangyue05.github.io/'>Yue Huang</a>*,...",match:"European Conference on Computer Vision (ECCV), 2022",match2:"",paper:"[論文]",projectPage:"",code:"[コード]",video:""}],journalTitle:"ジャーナル論文",journalPublication:[{name:"暂無"}],patentTitle:"発明特许",patent:[{name:"アナログ信号処理ベースのヒューマンインタラクション感知装置",author:'<a href="#">林 涅</a>、劉 嬋梓、黎 浩鋒、鄒 世豪、李 俊裕',number:"CN 202022246705.5"}],copyrghtTitle:"ソフトウエア著作権",softwareCopyrght:[{name:"日本郵便の支払伝票OCR認識システム",Number:"ソフトウエア著作権 No.A0003976"},{name:"人工知能による映像著作権保護システム",Number:"ソフトウエア著作権 No.4840268"}],projectsTitle:"プロジェクト",projectsHightLight:"Highlighted",projectsNote:" は最近取り組んだプロジェクトについて言及した。",recentlyProjects:[{name:"EgoV: リアルとバーチャルの自己中心的なビデオの全く新しいデータセットです",author:"<strong>!! 新しい長期プロジェクトとして修士課程で始めます !!</strong>",match:"",match2:"",paper:"[研究計画書]",projectPage:"[プロジェクト ページ]",code:"[コード]",video:"[ビデオ]"},{name:"自己中心ビデオの手領域に基づく監督のない領域適応一人称動作認識",author:"<strong>林 涅</strong>, 蔡 敏捷",match:"湖南大学",match2:"",paper:"[論文]",projectPage:"[プロジェクト ページ]",code:"[コード]",video:"[ビデオ]",photo:"[会議の写真]"},{name:"移動学習による知識濃縮蒸留",author:"李 宸鑫, 林 明寶, <strong>林 涅</strong>, 莊 毅鴻, 黃 悅",match:"廈門大学 & 湖南大学",paper:"[論文]",projectPage:"[プロジェクト ページ]",code:"[コード]",video:"[ビデオ]"},{name:"一人称視点でのデータ収集 (ヘッドマウントカメラによる)",author:"<strong>林 涅</strong>",match:"湖南大学",paper:"",projectPage:"",code:"",video:""}],pastProjects:[{name:"拡張残差縮小ネットワークによるデジタル画像ノイズ除去",author:"<strong>林 涅</strong>, 陳 高, 周 清峰, 劉 嬋梓",match:"産業用人工知能技術研究所 (IIAIT)",match2:"",paper:"[論文]",projectPage:"",code:"",video:"",photo:"[会議の写真]"},{name:"マルチモダリティ ビデオ分析と理解",author:"<strong>林 涅</strong>, 郭 凡, 王 傑, 丁 燁, 廖 清",match:"ハルビン工業大学 (HIT) ",match2:"",paper:"",projectPage:"",code:"",video:""},{name:"OpenMVマシンビジョンによる ハン-ドボール 動作認識制御システム",author:"<strong>林 涅</strong>, 王 斌, 周 清峰",match:"中国人工知能電子デザインコンテスト",match2:"",paper:"",projectPage:"",code:"",video:""}],scientificFundTitle:"研究ファンド",scientificFund:[{name:'<a href="#">国家自然科学ファンド</a>',match:"国家自然科学ファンド号：No. 61971138"},{name:"広東省基礎と応用基礎研究助成プロジェクト",match:"项目基金号：No. 2019A1515111149"},{name:"広東省高等教育イノベーションと高校発展プロジェクト",match:"工程基金号：No. 2020ZDZX3047"}],footer:{period:"© 2018 - 2022  リン ネエ",lastUpdated:"前回のアップデート: 2022年8月31日"}};var mt=ft;const bt={__identity:"中文",__langKey:"zh",name:"林 涅",degree:"本科生 (毕业于 2022.06)",major:"计算机 & 软件工程专业 (GPA: 3.6 排名: 专业 第1st/78 名)",academy:"助理研究员",department:"信息科学与工程学院, 湖南大学",researchStudent:"（现在）",personalIntroduction:'Hi! 我叫<strong>林涅</strong>，我于2022年6月在东莞理工大学取得工学学士学位。我现在正在\n  <a href="https://www.hnu.edu.cn/" target="_blank">\n  湖南大学</a>\n  担任研究助理，\n  同时指导我学术科研的导师是\n  <a href="http://csee.hnu.edu.cn/people/caiminjie" target="_blank">\n  蔡 敏捷</a>\n  教授。\n  <br>我的研究兴趣包括<strong>计算机视觉(CV)</strong>，特别是在<strong>第一人称视觉(FPV)</strong> 以及<strong>人机交互(HCI)</strong>，\n  特别是计算机视觉应用在<strong>感知和理解与人类相关的活动</strong>的领域。\n  我对计算机视觉中的第一人称视觉有着浓厚的兴趣与爱好，欢迎各位通过我的邮箱与我联系与交流。',notification1:'<img src="http://www.linnie.com.cn/img/new.gif">：<br>\n  (a) 我的现状：我正在寻找计算机视觉中第一人称视觉方向的研究室，并申请该研究室所在大學的硕士课程以及博士课程。<br>\n  (b) 我的研究：我在未來的研究目標是希望通過對计算机视觉中第一人稱視角的探索和發現來構建更加强大的以人為中心的‘思考’型人工智能！<br>\n  (c) 我的目標：我的目標是成爲一名计算机视觉科研人员，未來在大学擔任独立的指导老师，在世界範圍做出令人印象深刻且有影响力的工作。<br>\n  (d) 我的規劃：我在完成硕士阶段課程后會继续完成博士課程，以此不斷提升我的科研能力。<br><br>\n  以下是關於我的申請材料（學術）：\n  ',curriculum_vitae:"1. [個人簡歷]",academic_transcripts:"2. [成績單]",research_proposal:"3. [研究計劃書]",project_page:"[項目頁面]",meeting_photo:"4. [参加CVPR会议]",recommendation_letter:"5. [推薦信-蔡敏捷教授]",research_certificate:"6. [研究證明-湖南大學]",PRC_scholarship:"7. [中華人民共和國獎學金]",notification2:"以下是關於我的申請材料（基礎）：\n  ",diploma_certificate:"8. [毕业证明]",bachelor_certificate:"9. [学士学位证明]",ranking_certificate:"10. [年级排位证明]",address1:"地址1: 中国广东省东莞市松山湖 东莞理工大学 Ai-Net智能研究所 9A-411",address:"地址: 中国湖南省长沙市湖南大学 信息科学与工程学院 研究生办公室433 （现在）",email:"个人邮箱: nielin@hnu.edu.cn",phone:"个人电话: +86 131-3835-0137",web:"个人网站: linnie.com.cn",newTitle:"消息",navigation:{name:"林涅",address:["主页","消息","研究兴趣","论文发表","项目经验","个人经历","专业经验","荣誉奖项","发表专利","软件著作","参与基金"]},new:{new1:"[ 2019.08 ] 在Prof. Lvy Wang的指导下，我在<strong>加拿大多伦多大学</strong>完成了一个关于数学与机器学习的研究项目。为我以后关于<strong>计算机视觉</strong>的研究奠定数学基础。",new2:"[ 2019.12 ] 我以年级第一的优异成绩获得了2019年的<strong>一等奖学金</strong>。谢谢!",new3:"[ 2020.03 ] 在大二寒假期间，我在<strong>哈尔滨工业大学（深圳）</strong>廖教授的指导下参与研究实习，通过深度学习完成关于<strong>视频理解与分析</strong>项目。",new4:"[ 2020.08 ] 我在<strong>新加坡国立大学</strong>完成了<strong>人工智能与深度学习</strong>领域的项目学习。并获得由新加坡国立大学颁发的<strong>荣誉奖</strong>。",new5:"[ 2020.09 ] 恭喜，我通过层层选拔加入<strong>工业人工智能技术研究院(IIAIT)</strong>，并由来自<strong>清华大学</strong>的陈高教授指导展开关于数字图像处理方面的研究。",new6:"[ 2020.10 ] 我获得中国人工智能电子设计大赛三等奖 !!",new7:"[ 2020.12 ] 我以年级第一的优异成绩获得了2020年的<Strong>一等奖学金</Strong>以及<Strong> 高伟光企业奖学金(杰出工程代表) </Strong>。谢谢!",new8:'[ 2021.01 ] 我们团队以<Strong>13/2207</Strong>的排名进入<a href="https://www.ccf.org.cn/en/">中国计算机学会(CCF) </a> <Strong>人工智能视觉算法大赛</Strong>决赛。一次很赞的团队合作体验!!',new9:"[ 2021.05 ] 我在美国数学建模竞赛USA MCM/ICM 中获得<Strong>国际二等奖</Strong>。",new10:"[ 2021.06 ] 开始在湖南大学的計算機視覺实验室担任 <Strong>研究助理</Strong>。 由<a href='https://cai-mj.github.io/'>蔡 敏捷</a>教授担任指导老师。<a href=\"https://www.linnie.com.cn/documents/Research_Assistant_Minjie_Cai_Hunan_University.pdf\">[研究證明]</a>",new11:"[ 2021.10 ] 我从我们的实验室得到了属于我自己的<Strong>头戴式相机</Strong>，未来将尝试收集第一人称数据集。谢谢!",new12:"[ 2021.12 ] 我以年级第一的优异成绩获得了2021年的<Strong>一等奖奖学金</Strong>、<Strong>岭南学术奖学金(优秀学术代表)</Strong>，谢谢!",new13:"[ 2022.05 ] 恭喜! 我获得了<a href='http://www.moe.gov.cn/jyb_xxgk/s5743/s5744/A05/202112/t20211216_587869.html'>中华人民共和国国家奖学金</a>, 由<a href='http://en.moe.gov.cn/'>中华人民共和国教育部</a>颁布, 这是中国最高级别的奖学金项目! (<Strong>全国排名前0.01%的学生</Strong>).",new14:"[ 2022.06 ] 我的毕业论文<strong>《基于自我中心视频中无监督域适应的第一人称动作识别》</strong>顺利通过了本科毕业设计论文答辩。",new15:"[ 2022.06 ] 恭喜! 我以<strong>专业第一名</strong>(<strong>Rank 1st / 78</strong>)取得<a>工学学士</a>，并且顺利毕业于<a>东莞理工 计算机软件工程专业</a>， 获得<strong>优秀本科毕业生</strong>。",new16:'[ 2022.06 ] 恭喜! 我的论文在<a href="https://eyewear-computing.org/EPIC_CVPR22/">CVPR-EPIC 2022</a>中关于<Strong>无监督域适应第一人称动作识别</Strong>顺利被接收, 在<a href="https://cai-mj.github.io/">蔡 敏捷</a>教授的指导下。 预印本和代码均可用. <a href="https://arxiv.org/abs/2207.03095">[預印本]</a> <a href="https://github.com/lin-nie/EPIC-KITCHENS-C4-UDA">[Github代码]</a>',new17:'[ 2022.07 ] 我受邀参加今年<a href="https://cvpr2022.thecvf.com/">CVPR 2022</a> 并参与 <a href="https://eyewear-computing.org/EPIC_CVPR22/">EPIC 2022</a> 演讲。<br><a href="./img/cvpr_2022_meeting_photo1.png">[會議照片1]&<a><a href="./img/cvpr_2022_meeting_photo2.png">[會議照片2]&<a><a href="./img/cvpr_2022_meeting_photo3.png">[會議照片3]&<a><a href="./img/cvpr_2022_meeting_photo4.png">[會議照片4]&<a><a href="./img/cvpr_2022_meeting_photo5.png">[會議照片5]&<a><a href="./img/cvpr_2022_meeting_photo6.png">[會議照片6]<a>',new18:'[ 2022.07 ] 我们关于<Strong>知识迁移学习</Strong>的论文已经被今年的<Strong>ECCV 2022</Strong>正式接受!! 代码已经开源。<a href="https://arxiv.org/pdf/2207.05409.pdf">[論文]</a><a href="https://arxiv.org/abs/2207.05409">[預印本]</a><a href="https://github.com/dzy3/KCD">[Github代碼]</a>',new19:'[ 2022.08 ] 在<a href="https://cai-mj.github.io/">蔡 敏捷</a>教授的指导下，我在今年的<Strong>BMVC 2022</Strong>上提交了一篇<Strong>基于自我中心视频中手部区域与第一人称动作识别相关的</Strong>论文。代码将会开源！！',new20:'[ 2022.09 ] 我非常希望我能尽快申请研究生和硕士，开始我的新项目:<Strong>EgoV: 从虚拟到现实</Strong>。<a href="http://www.linnie.com.cn/projects/egov/">[项目页面]</a><a href="http://www.linnie.com.cn/documents/NieLin_HNU_UTokyo_EgoV_Research_Proposal.pdf">[研究计划书]</a>'},biographyTitle:"个人经历",biography:{bio1:{introduce:"(2021.6-至今)  助理研究员. 指导教授为",mentor:"蔡 敏捷",brief1:"信息科学与工程学院, 计算机视觉实验室",brief2:"湖南大学"},bio2:{introduce:"(2018.9 - 2022.6)  计算机软件工程在读 (毕业于 2022.06)",brief1:"工业人工智能技术研究所 (IIAIT)",brief2:"东莞理工大学"}},exchangeTitle:"专业经验",exchangeSubtitle:"本人非常热衷于科研交流，以下为经常交流学习的大学：",exchange:[{imgName:"清华大学",href:"https://www.tsinghua.edu.cn/en/",intro:'<p style="font-size: 20px">\n              清華大学\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学排名ーーNo.17\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学排名ーーNo.28\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学排名ーーNo.20\n              </p>\n              <br><p style="font-size: 15px">\n              ARWU 2021: 世界大学排名ーーNo.29\n              </p>\n                '},{imgName:"NUS",href:"https://www.nus.edu.sg/",intro:'<p style="font-size: 20px">\n              シンガポール国立大学（NUS）\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学排名ーーNo.11\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学排名ーーNo.32\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学排名ーーNo.25\n              </p>\n              <br><p style="font-size: 15px">\n\n              </p>\n      '},{imgName:"TORONTO",href:"https://www.utoronto.ca/",intro:'<p style="font-size: 20px">\n              トロント大学（UofT）\n              </p> \n              <br><p style="font-size: 14.9px">\n              QS 2021: 世界大学排名ーーNo.26\n              </p>\n              <br><p style="font-size: 14.9px">\n              U.S. New : 世界大学排名ーーNo.17\n              </p>\n              <br><p style="font-size: 14.9px">\n              THE 2021: 世界大学排名ーーNo.18\n              </p>\n              <br><p style="font-size: 14.9px">\n              ARWU 2021: 世界大学排名ーーNo.23\n              </p>\n      '},{imgName:"香港科技大学",href:"https://hkust.edu.hk/",intro:'\n              <p style="font-size: 20px">\n              ホンコン科技大学（HKUST）\n              </p> \n              <br><p style="font-size: 15px">\n              QS 2021: 世界大学排名ーーNo.34\n              </p>\n              <br><p style="font-size: 15px">\n              U.S. New : 世界大学排名ーーNo.109\n              </p>\n              <br><p style="font-size: 15px">\n              THE 2021: 世界大学排名ーーNo.56\n              </p>\n              <br><p style="font-size: 15px">\n           \n              </p>\n      '}],profExprience:[{name:"1. 湖南大学 (HNU)",workplace:"长沙, 中国",topic:"研究课题: 基于手部区域的第一人称动作识别",title:"助理研究员",supervisor:" 指导教授: 蔡 敏捷 教授 [湖南大学]"},{name:"2. 工业人工智能技术研究所 (IIAIT)",workplace:"东莞, 中国",topic:"研究课题: 数字图像处理",title:"助理研究员",supervisor:" 指导教授: 陈高教授 [清华大学]"},{name:"3. 哈尔滨工业大学 (HIT)",workplace:"深圳, 中国",topic:"研究课题: 视频分析与理解",title:"研究实习生",supervisor:" 指导教授: 廖清教授 [哈尔滨工业大学(深圳)]"},{name:"4. 多伦多大学 (UofT)",workplace:"多伦多, 加拿大",topic:"研究课题: 数学与机器学习",title:"项目学生",supervisor:" 指导教授: Lvy Wang教授 [多伦多大学]"}],researchTitle:"研究兴趣",overallField:"整体领域",researchOverInterest:["计算机视觉 (CV)","第一人称视觉 (FPV)","人机交互 (HCI),"],specialField:"特别兴趣",researchSpecialInterest:["1. 自我中心的视频理解和分析","2. 动作识别","3. 手部区域分析","4. 域适应与泛化","5. 知识迁移学习",".........................."],awardsTitle:"荣誉奖项",scholarship:"所获奖学金",scholar1:"1. 中华人民共和国国家奖学金",scholar1explain:"[中华人民共和国教育部]",scholar1supp:"(中国排名前0.1%的学生)",scholar2:"2. 岭南学术奖学金  [杰出的学术代表]",scholar3:"3. 2021年学年度一等奖奖学金   [年级GPA第一名，2021年]",scholar4:"4. 高伟光企业奖学金   [杰出的工程代表]",scholar5:"5. 2020年学年度一等奖奖学金   [年级GPA第一名，2020年]",scholar6:"6. 2019年学年度一等奖奖学金   [年级GPA第一名，2019年]",awards:[{subtitle:"奖励",content:["广东省优秀本科毕业生","优秀本科生的论文","美国数学建模竞赛国际二等奖","中国计算机学会AI视觉算法大赛 (排名13/2207)","中国人工智能电子设计大赛三等奖","新加坡国立大学荣誉奖","华为优秀开发者奖"]}],conferenceTitle:"论文发表",conferencePublication:[{name:"EPIC-KITCHENS-100 Unsupervised Domain Adaptation Challenge for Action Recognition 2022 Technical Report",author:"<Strong>Nie Lin</Strong>, <a href='https://cai-mj.github.io/' target=\"_blank\">Minjie Cai</a><sup>✉</sup>",match:"IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR-EPIC), 2022",match2:"",paper:"[论文]",projectPage:"[项目页面]",code:"[Github代码]",video:"[视频]"},{name:"Knowledge Condensation Distillation",author:"Chenxin Li, <a href='https://lmbxmu.github.io/'>Mingbao Lin</a>, Zhiyuan Ding, <Strong>Nie Lin</Strong>, Yihong Zhuang, <a href='https://huangyue05.github.io/'>Yue Huang</a><sup>✉</sup>,...",match:"European Conference on Computer Vision (ECCV), 2022",match2:"",paper:"[论文]]",projectPage:"",code:"[Github代码]",video:""}],journalTitle:"期刊论文",journalPublication:[{name:"暂无"}],patentTitle:"发表专利",patent:[{name:"基于模拟信号处理的人机交互感知设备",author:'<a href="#">林涅</a>, 刘婵梓博士, 黎浩锋, 邹世豪, 李俊裕',number:"CN 202022246705.5"}],copyrghtTitle:"软件著作",softwareCopyrght:[{name:"日文邮政支付票据 OCR识别安卓客户端App（日文邮政票 OCR App）",Number:"软著登字第 A0003976号"},{name:"基于人工智能的视频版权保护系统",Number:"软著登字第 4840268号"}],projectsTitle:"项目经验",projectsHightLight:"高亮",projectsNote:" 表示最近开展的项目。",recentlyProjects:[{name:"EgoV: 一个全新的跨越真实和虚拟的以自我中心视频的数据集",author:"<strong>！！作为一个全新的长期项目，将会在我硕士阶段展开！！</strong>",match:"",match2:"",paper:"[研究计划书]",projectPage:"[项目页面]",code:"[Github代码]",video:"[视频]"},{name:"基于自中心视频手部区域的无监督域适应第一人称动作识别",author:"<strong>林 涅</strong>, 蔡 敏捷",match:"湖南大学",match2:"",paper:"[论文]",projectPage:"[项目页面]",code:"[Github代码]",video:"[视频]",photo:"[会议照片]"},{name:"基于迁移学习的知识浓缩蒸馏",author:"李 宸鑫, 林 明宝, <strong>林 涅</strong>, 庄毅鸿, 黄悦",match:"厦门大学 & 湖南大学",paper:"[论文]",projectPage:"[项目页面]",code:"[Github代码]",video:"[视频]"},{name:"第一人称视角下的数据集采集 (通过头戴式摄像头)",author:"<strong>林 涅</strong>",match:"湖南大学",paper:"",projectPage:"",code:"",video:""}],pastProjects:[{name:"基于扩张残差收缩网络的数字图像去噪",author:"<strong>林 涅</strong>, 陈 高, 周 清峰, 刘 婵梓",match:"工业人工智能技术研究所 (IIAIT)",match2:"",paper:"[论文]",projectPage:"",code:"",video:"",photo:"[会议照片]"},{name:"多模态视频分析与理解",author:"<strong>林 涅</strong>, 郭 凡, 王 杰, 丁 烨, 廖 清",match:"哈尔滨工业大学 (HIT) ",match2:"",paper:"",projectPage:"",code:"",video:"[video]"},{name:"基于OpenMV机器视觉的手球动作识别控制系统",author:"<strong>林 涅</strong>, 王 斌, 周 清峰",match:"中国人工智能电子设计大赛",match2:"",paper:"",projectPage:"",code:"",video:""}],scientificFundTitle:"参与基金",scientificFund:[{name:'<a href="#">国家自然科学基金</a>',match:"国家自然科学基金号：No. 61971138"},{name:"广东省基础与应用基础研究资助项目",match:"项目基金号：No. 2019A1515111149"},{name:"广东省高等教育创新与高校发展工程",match:"工程基金号：No. 2020ZDZX3047"}],footer:{period:"© 2018 - 2022   林涅",lastUpdated:"上次更新: 2022年8月31日"}};var wt=bt;r["a"].use(lt["a"]);var _t=new lt["a"].Store({state:{words:ut,dictionary:{en:ut,zh:wt,jp:mt}},mutations:{SET_LANGUAGE(e,t){e.words=e.dictionary[t]}},actions:{setLanguage({commit:e},t){e("SET_LANGUAGE",t)}},getters:{words(e){return e.words}},modules:{}}),vt=(n("63bf"),n("ecee")),yt=n("c074"),Ct=n("b702"),Pt=n("f2d1"),jt=n("ad3d");vt["c"].add(yt["a"],Ct["a"],Pt["a"]),r["a"].component("font-awesome-icon",jt["a"]),r["a"].component("font-awesome-layers",jt["b"]),r["a"].component("font-awesome-layers-text",jt["c"]),r["a"].config.productionTip=!1,new r["a"]({store:_t,render:e=>e(ht)}).$mount("#app")},cfa2:function(e,t,n){e.exports=n.p+"img/xx.5a35d7e2.png"},d268:function(e,t,n){"use strict";n("1c8f")},d4d5:function(e,t,n){var r={"./0.gif":"0db5","./1.gif":"2d4f","./2.gif":"4382","./3.gif":"d6b6"};function o(e){var t=i(e);return n(t)}function i(e){if(!n.o(r,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return r[e]}o.keys=function(){return Object.keys(r)},o.resolve=i,e.exports=o,o.id="d4d5"},d6b6:function(e,t,n){e.exports=n.p+"img/3.9c599d8e.gif"},dde4:function(e,t,n){"use strict";n("62c3")},e429:function(e,t,n){e.exports=n.p+"img/image.a6041b50.png"},e466:function(e,t,n){var r={"./0.png":"0554","./1.png":"064c"};function o(e){var t=i(e);return n(t)}function i(e){if(!n.o(r,e)){var t=new Error("Cannot find module '"+e+"'");throw t.code="MODULE_NOT_FOUND",t}return r[e]}o.keys=function(){return Object.keys(r)},o.resolve=i,e.exports=o,o.id="e466"},f0d4:function(e,t,n){},fbd7:function(e,t,n){"use strict";n("728c")}});
//# sourceMappingURL=app.9fa47d9c.js.map